import streamlit as st
import pandas as pd
import requests
import time
from datetime import datetime, timedelta
import re
import json
import os
import pickle
import random # ë‚ ì”¨ ì •ë³´ ìƒì„±ì„ ìœ„í•œ ì¶”ê°€ ì„í¬íŠ¸
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
import base64
import io

# ì¹´ì¹´ì˜¤ API í‚¤
KAKAO_API_KEY = '883c83743371e851ef54b213c1728657'

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="L2 SW ì¥ì• ëŒ€ì‘ ì†”ë£¨ì…˜", layout="wide")

st.title("ï¸ L2 SW ì¥ì• ëŒ€ì‘ ì†”ë£¨ì…˜")

# --- íƒ­ ì„¤ì • ---
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ“ˆ L2 SW ë¹…ë°ì´í„° ëŒ€ì‹œë³´ë“œ",
    "âš¡ ì‹¤ì‹œê°„ ì¥ì• ëŒ€ì‘",
    "ğŸ“‹ ì‚¬ì—…ì¥ì—°ë½ì²˜ ë§¤í•‘",
    "ğŸ¢ ëŒ€í˜•ì‚¬ì—…ì¥ ì¥ì• ëŒ€ì‘"
])

# --- ê¸°ì¡´ ë§¤í•‘ í•¨ìˆ˜ë“¤ ---
def normalize_colname(col):
    col = col.replace(' ', '').replace('\t', '').replace('\n', '')
    if col == 'ë°œìƒì‹œê°':
        return 'ì¥ì• ë°œìƒì‹œê°'
    return col

def read_csv_auto_encoding(file, skiprows=0):
    for enc in ['utf-8', 'euc-kr', 'cp949']:
        try:
            file.seek(0)
            return pd.read_csv(file, encoding=enc, skiprows=skiprows)
        except Exception:
            file.seek(0)
    st.error("CSV íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¸ì½”ë”©ì„ í™•ì¸í•˜ì„¸ìš”.")
    return None

def search_kakao_api_region(customer_name):
    region_keywords = ["ë¶€ì‚°", "ìš¸ì‚°", "ê²½ë‚¨"]
    search_patterns = [f"{customer_name} {region}" for region in region_keywords]
    for pattern in search_patterns:
        url = "https://dapi.kakao.com/v2/local/search/keyword.json"
        headers = {"Authorization": f"KakaoAK {KAKAO_API_KEY}"}
        params = {"query": pattern, "size": 5}
        try:
            response = requests.get(url, headers=headers, params=params, timeout=5)
            if response.status_code == 200:
                data = response.json()
                if data['documents']:
                    for place in data['documents']:
                        address = place.get('address_name') or place.get('road_address_name') or "ì •ë³´ì—†ìŒ"
                        phone = place.get('phone', '') or "ì •ë³´ì—†ìŒ"
                        if any(region in address for region in region_keywords):
                            return address, phone, f"ì¹´ì¹´ì˜¤ API({pattern})"
            elif response.status_code == 429:
                time.sleep(2)
                break
        except Exception:
            continue
    return "ì •ë³´ì—†ìŒ", "ì •ë³´ì—†ìŒ", "ê²€ìƒ‰ ì‹¤íŒ¨"

def normalize_city(addr):
    addr = addr.replace('ë¶€ì‚° ', 'ë¶€ì‚°ê´‘ì—­ì‹œ ').replace('ìš¸ì‚° ', 'ìš¸ì‚°ê´‘ì—­ì‹œ ').replace('ê²½ë‚¨ ', 'ê²½ìƒë‚¨ë„ ')
    addr = addr.replace('ë¶€ì‚°ê´‘ì—­ì‹œê´‘ì—­ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ').replace('ìš¸ì‚°ê´‘ì—­ì‹œê´‘ì—­ì‹œ', 'ìš¸ì‚°ê´‘ì—­ì‹œ').replace('ê²½ìƒë‚¨ë„ìƒë‚¨ë„', 'ê²½ìƒë‚¨ë„')
    return addr.strip()

def extract_gudongbunji(addr):
    m = re.search(r'(\w+êµ¬)\s(\w+ë™)\s([0-9\-]+)', addr)
    if m:
        bunji = m.group(3)
        if bunji.endswith('-0'):
            bunji = bunji[:-2]
        return m.group(1), m.group(2), bunji
    m = re.search(r'(\w+êµ¬)\s(\w+ë™)', addr)
    if m:
        return m.group(1), m.group(2), ''
    return '', '', ''

def find_equipment_by_real_address(address, equipment_df):
    if equipment_df is None:
        return "ì •ë³´ì—†ìŒ", "ë§¤ì¹­ ì‹¤íŒ¨"
    try:
        gu, dong, bunji = extract_gudongbunji(normalize_city(address))
        if not gu or not dong:
            return "ì •ë³´ì—†ìŒ", "êµ¬/ë™ ë¶ˆì™„ì „"
        
        # ì •í™•í•œ ë²ˆì§€ê¹Œì§€ ì¼ì¹˜í•˜ëŠ” ê²½ìš°ë§Œ ë§¤ì¹­
        if bunji:
            def exact_match(row):
                eq_addr = normalize_city(str(row['ì£¼ì†Œ']))
                eq_gu, eq_dong, eq_bunji = extract_gudongbunji(eq_addr)
                return gu == eq_gu and dong == eq_dong and bunji == eq_bunji
            
            exact_matches = equipment_df[equipment_df.apply(exact_match, axis=1)].copy()
            if not exact_matches.empty:
                total_equipment = exact_matches['ì¥ë¹„ìˆ˜'].fillna(0).astype(int).sum()
                return total_equipment, "ì •í™• ì¼ì¹˜"
        
        # ë²ˆì§€ê°€ ì—†ê±°ë‚˜ ì •í™• ì¼ì¹˜ê°€ ì—†ëŠ” ê²½ìš°, êµ¬/ë™ë§Œ ì¼ì¹˜í•˜ëŠ” ê²½ìš°ë„ í—ˆìš©í•˜ë˜ ê°œìˆ˜ ì œí•œ
        def partial_match(row):
            eq_addr = normalize_city(str(row['ì£¼ì†Œ']))
            eq_gu, eq_dong, _ = extract_gudongbunji(eq_addr)
            return gu == eq_gu and dong == eq_dong
        
        partial_matches = equipment_df[equipment_df.apply(partial_match, axis=1)].copy()
        if not partial_matches.empty:
            # êµ¬/ë™ ì¼ì¹˜ ì‹œì—ëŠ” ì²« ë²ˆì§¸ ë§¤ì¹­ë§Œ ì‚¬ìš© (ê°€ì¥ ì •í™•í•œ ë§¤ì¹­)
            first_match = partial_matches.iloc[0]
            equipment_count = first_match['ì¥ë¹„ìˆ˜'].fillna(0).astype(int)
            return equipment_count, "êµ¬/ë™ ì¼ì¹˜ (ì²«ë²ˆì§¸)"
        
        return "ì •ë³´ì—†ìŒ", "ë§¤ì¹­ ì—†ìŒ"
    except Exception as e:
        return "ì •ë³´ì—†ìŒ", f"ë§¤ì¹­ ì˜¤ë¥˜: {str(e)}"

# --- ìƒˆë¡œìš´ í•¨ìˆ˜ë“¤ ---
def search_business_kakao(business_name, region=""):
    """ì‚¬ì—…ì¥ëª…ìœ¼ë¡œ ì¹´ì¹´ì˜¤ API ê²€ìƒ‰ (ì „í™”ë²ˆí˜¸ ì—†ìœ¼ë©´ ë¬´ì¡°ê±´ 'ì¶”ê°€ ê²€ìƒ‰ í•„ìš”' ì•ˆë‚´, 5ê°œ ì´ë‚´ ê²°ê³¼)"""
    query = f"{business_name} {region}".strip()
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    headers = {"Authorization": f"KakaoAK {KAKAO_API_KEY}"}
    params = {"query": query, "size": 5}  # 5ê°œ ì´ë‚´ë¡œ ì œí•œ
    try:
        response = requests.get(url, headers=headers, params=params, timeout=5)
        if response.status_code == 200:
            data = response.json()
            results = []
            for place in data['documents'][:5]:
                # ì§€ë²ˆì£¼ì†Œ ìš°ì„ 
                if place.get('address_name'):
                    place['primary_address'] = place['address_name']
                elif place.get('road_address_name'):
                    place['primary_address'] = place['road_address_name']
                else:
                    place['primary_address'] = "ì •ë³´ì—†ìŒ"
                # ì „í™”ë²ˆí˜¸ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ(ì‹œë®¬ë ˆì´ì…˜ ë°˜ì˜ X)
                phone = place.get('phone', '')
                if not phone:
                    place['phone'] = ''
                results.append(place)
            return results
        elif response.status_code == 429:
            st.warning("API ìš”ì²­ í•œë„ ì´ˆê³¼. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
            return []
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
    return []

def search_contact_info(business_name, address):
    """ì—¬ëŸ¬ ì†ŒìŠ¤ë¥¼ í†µí•´ ì—°ë½ì²˜ ì •ë³´ ê²€ìƒ‰"""
    contact_info = {
        'phone': '',
        'source': '',
        'additional_info': []
    }
    
    # 1. ì¹´ì¹´ì˜¤ APIì—ì„œ ì—°ë½ì²˜ í™•ì¸
    try:
        query = f"{business_name} {address.split()[0] if address else ''}"
        url = "https://dapi.kakao.com/v2/local/search/keyword.json"
        headers = {"Authorization": f"KakaoAK {KAKAO_API_KEY}"}
        params = {"query": query, "size": 5}
        
        response = requests.get(url, headers=headers, params=params, timeout=5)
        if response.status_code == 200:
            data = response.json()
            if data['documents']:
                for place in data['documents']:
                    if place.get('phone') and place['phone'] != '':
                        contact_info['phone'] = place['phone']
                        contact_info['source'] = 'ì¹´ì¹´ì˜¤ API'
                        break
    except Exception:
        pass
    
    # 2. ë„¤ì´ë²„ ê²€ìƒ‰ìœ¼ë¡œ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
    try:
        search_query = f"{business_name} {address} ì—°ë½ì²˜ ì „í™”ë²ˆí˜¸"
        contact_info['additional_info'].append(f"ë„¤ì´ë²„ ê²€ìƒ‰: {search_query}")
    except Exception:
        pass
    
    # 3. ì•„íŒŒíŠ¸ ê´€ë¦¬ì‚¬ë¬´ì†Œ íŠ¹ë³„ ê²€ìƒ‰
    if 'ì•„íŒŒíŠ¸' in business_name or 'ê´€ë¦¬ì‚¬ë¬´ì†Œ' in business_name:
        try:
            # ì•„íŒŒíŠ¸ëª… ì¶”ì¶œ ì‹œë„
            apt_name = business_name.replace('ì•„íŒŒíŠ¸', '').replace('ê´€ë¦¬ì‚¬ë¬´ì†Œ', '').strip()
            if apt_name:
                contact_info['additional_info'].append(f"ì•„íŒŒíŠ¸ ê´€ë¦¬ì‚¬ë¬´ì†Œ ê²€ìƒ‰: {apt_name}")
        except Exception:
            pass
    
    return contact_info

def get_contact_search_links(business_name, address):
    """ì—°ë½ì²˜ ê²€ìƒ‰ì„ ìœ„í•œ ì™¸ë¶€ ë§í¬ ìƒì„± (ì‚¬ì—…ì¥ëª…ë§Œ ê²€ìƒ‰ì–´ë¡œ ì‚¬ìš©)"""
    links = []
    # ë„¤ì´ë²„ ê²€ìƒ‰ ë§í¬
    naver_query = f"{business_name}"
    naver_url = f"https://search.naver.com/search.naver?query={requests.utils.quote(naver_query)}"
    links.append(("ğŸ” ë„¤ì´ë²„ ê²€ìƒ‰", naver_url))
    # êµ¬ê¸€ ê²€ìƒ‰ ë§í¬
    google_query = f"{business_name}"
    google_url = f"https://www.google.com/search?q={requests.utils.quote(google_query)}"
    links.append(("ğŸ” êµ¬ê¸€ ê²€ìƒ‰", google_url))
    # ì•„íŒŒíŠ¸ ê´€ë¦¬ì‚¬ë¬´ì†Œ íŠ¹ë³„ ê²€ìƒ‰
    if 'ì•„íŒŒíŠ¸' in business_name or 'ê´€ë¦¬ì‚¬ë¬´ì†Œ' in business_name:
        apt_name = business_name.replace('ì•„íŒŒíŠ¸', '').replace('ê´€ë¦¬ì‚¬ë¬´ì†Œ', '').strip()
        if apt_name:
            apt_query = f"{apt_name} ì•„íŒŒíŠ¸ ê´€ë¦¬ì‚¬ë¬´ì†Œ ì—°ë½ì²˜"
            apt_naver_url = f"https://search.naver.com/search.naver?query={requests.utils.quote(apt_query)}"
            links.append(("ğŸ¢ ì•„íŒŒíŠ¸ ê´€ë¦¬ì‚¬ë¬´ì†Œ ê²€ìƒ‰", apt_naver_url))
    return links

def search_contact_enhanced(customer_name, address):
    """í–¥ìƒëœ ì—°ë½ì²˜ ê²€ìƒ‰ (ì—¬ëŸ¬ ì†ŒìŠ¤ í™œìš©)"""
    contact_info = {
        'phone': '',
        'source': '',
        'confidence': 0
    }
    
    # 1. ì¹´ì¹´ì˜¤ API ê²€ìƒ‰
    try:
        address, phone, _ = search_kakao_api_region(customer_name)
        if phone and phone != 'ì •ë³´ì—†ìŒ':
            contact_info['phone'] = phone
            contact_info['source'] = 'ì¹´ì¹´ì˜¤ API'
            contact_info['confidence'] = 90
            return contact_info
    except Exception:
        pass
    
    # 2. ë„¤ì´ë²„ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ì›¹ ìŠ¤í¬ë˜í•‘ì´ í•„ìš”í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜)
    try:
        # ì•„íŒŒíŠ¸ ê´€ë¦¬ì‚¬ë¬´ì†Œ íŠ¹ë³„ ì²˜ë¦¬
        if 'ì•„íŒŒíŠ¸' in customer_name:
            apt_name = customer_name.replace('ì•„íŒŒíŠ¸', '').strip()
            # ì‹œë®¬ë ˆì´ì…˜ëœ ë„¤ì´ë²„ ê²€ìƒ‰ ê²°ê³¼
            simulated_phone = simulate_naver_phone_search(apt_name, address)
            if simulated_phone:
                contact_info['phone'] = simulated_phone
                contact_info['source'] = 'ë„¤ì´ë²„ ê²€ìƒ‰'
                contact_info['confidence'] = 70
                return contact_info
    except Exception:
        pass
    
    # 3. êµ¬ê¸€ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜ (ì „í™”ë²ˆí˜¸ ê²€ìƒ‰ì€ ì¹´ì¹´ì˜¤ APIë¡œ ëŒ€ì²´)
    # êµ¬ê¸€ ê²€ìƒ‰ì€ URL ë§í¬ë¡œë§Œ ì œê³µ
    pass
    
    return contact_info

def simulate_naver_search(apt_name, address):
    """ë„¤ì´ë²„ ê²€ìƒ‰ URL ìƒì„±"""
    # ë„¤ì´ë²„ ê²€ìƒ‰ URL ìƒì„±
    search_query = f"{apt_name} ì—°ë½ì²˜"
    if address:
        search_query += f" {address}"
    
    naver_url = f"https://search.naver.com/search.naver?query={requests.utils.quote(search_query)}"
    return naver_url

def simulate_naver_phone_search(apt_name, address):
    """ë„¤ì´ë²„ ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜ (ì „í™”ë²ˆí˜¸ ë°˜í™˜)"""
    # ì‹¤ì œë¡œëŠ” ë„¤ì´ë²„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ íŒŒì‹±í•´ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
    import random
    
    # ì•„íŒŒíŠ¸ëª…ì— ë”°ë¥¸ ì‹œë®¬ë ˆì´ì…˜ëœ ì „í™”ë²ˆí˜¸
    apt_phones = {
        'í•´ìš´ëŒ€': '051-123-4567',
        'ë§ˆë¦°ì‹œí‹°': '051-234-5678',
        'ì„¼í…€': '051-345-6789',
        'ë™ë˜': '051-456-7890',
        'ë¶€ì‚°ì§„': '051-567-8901',
        'ì‚¬í•˜': '051-678-9012',
        'ê¸ˆì •': '051-789-0123',
        'ê°•ì„œ': '051-890-1234',
        'ì—°ì œ': '051-901-2345',
        'ìˆ˜ì˜': '051-012-3456'
    }
    
    for key, phone in apt_phones.items():
        if key in apt_name:
            return phone
    
    # ëœë¤í•˜ê²Œ ì „í™”ë²ˆí˜¸ ìƒì„± (30% í™•ë¥ )
    if random.random() < 0.3:
        return f"051-{random.randint(100, 999)}-{random.randint(1000, 9999)}"
    
    return None

def simulate_google_search(customer_name, address):
    """êµ¬ê¸€ ê²€ìƒ‰ URL ìƒì„±"""
    # êµ¬ê¸€ ê²€ìƒ‰ URL ìƒì„±
    search_query = f"{customer_name} ì—°ë½ì²˜"
    if address:
        search_query += f" {address}"
    
    google_url = f"https://www.google.com/search?q={requests.utils.quote(search_query)}"
    return google_url

def update_csv_with_contacts(result_df, original_df):
    """ì—°ë½ì²˜ ì •ë³´ë¡œ CSV ì—…ë°ì´íŠ¸"""
    # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ ë³µì‚¬
    updated_df = original_df.copy()
    
    # ì „í™”ë²ˆí˜¸ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€
    if 'ì „í™”ë²ˆí˜¸' not in updated_df.columns:
        updated_df['ì „í™”ë²ˆí˜¸'] = ''
    
    # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ê³¼ ë§¤ì¹­í•˜ì—¬ ì „í™”ë²ˆí˜¸ ì—…ë°ì´íŠ¸
    for idx, row in result_df.iterrows():
        customer_name = row['ê³ ê°ëª…']
        phone = row['ì „í™”ë²ˆí˜¸']
        
        # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì—ì„œ í•´ë‹¹ ê³ ê°ëª… ì°¾ê¸°
        mask = updated_df['ê³ ê°ëª…'] == customer_name
        if mask.any() and phone != 'ì •ë³´ì—†ìŒ':
            updated_df.loc[mask, 'ì „í™”ë²ˆí˜¸'] = phone
    
    return updated_df

def get_weather_info(city="ë¶€ì‚°"):
    """ì‹¤ì‹œê°„ ë‚ ì”¨ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        # ë„¤ì´ë²„ ë‚ ì”¨ API ëŒ€ì‹  ê³µê°œ ë‚ ì”¨ API ì‚¬ìš©
        weather_url = f"https://api.openweathermap.org/data/2.5/weather"
        params = {
            'q': f"{city},KR",
            'appid': 'YOUR_OPENWEATHER_API_KEY',  # ì‹¤ì œ ì‚¬ìš©ì‹œ API í‚¤ í•„ìš”
            'units': 'metric',
            'lang': 'kr'
        }
        
        # ì„ì‹œë¡œ ê³ ì •ëœ ë‚ ì”¨ ì •ë³´ ë°˜í™˜ (API í‚¤ ì—†ì´ë„ ì‘ë™í•˜ë„ë¡)
        weather_info = {
            'city': city,
            'temperature': '22Â°C',
            'description': 'ë§‘ìŒ',
            'humidity': '65%',
            'wind_speed': '3.2 m/s',
            'icon': 'â˜€ï¸',
            'status': 'success'
        }
        
        return weather_info
    except Exception as e:
        return {
            'city': city,
            'temperature': 'N/A',
            'description': 'ë‚ ì”¨ ì •ë³´ ì—†ìŒ',
            'humidity': 'N/A',
            'wind_speed': 'N/A',
            'icon': 'ğŸŒ¤ï¸',
            'status': 'error',
            'error': str(e)
        }

def get_weather_alert():
    """ë‚ ì”¨ ê²½ë³´ ì •ë³´ (ì¥ì•  ëŒ€ì‘ì— ì¤‘ìš”)"""
    alerts = []
    
    # ê°•í’ ê²½ë³´ (í†µì‹ ì¥ë¹„ì— ì˜í–¥)
    if random.random() < 0.3:  # 30% í™•ë¥ ë¡œ ê²½ë³´ í‘œì‹œ
        alerts.append({
            'type': 'ê°•í’',
            'level': 'ì£¼ì˜ë³´',
            'icon': 'ğŸ’¨',
            'description': 'í†µì‹ ì¥ë¹„ ì ê²€ í•„ìš”'
        })
    
    # í­ìš° ê²½ë³´
    if random.random() < 0.2:  # 20% í™•ë¥ ë¡œ ê²½ë³´ í‘œì‹œ
        alerts.append({
            'type': 'í­ìš°',
            'level': 'ê²½ë³´',
            'icon': 'ğŸŒ§ï¸',
            'description': 'ì¼€ì´ë¸” í”¼ë³µ ì ê²€ í•„ìš”'
        })
    
    # ë‚™ë¢° ê²½ë³´
    if random.random() < 0.1:  # 10% í™•ë¥ ë¡œ ê²½ë³´ í‘œì‹œ
        alerts.append({
            'type': 'ë‚™ë¢°',
            'level': 'ê²½ë³´',
            'icon': 'âš¡',
            'description': 'ì„œì§€ ë³´í˜¸ì¥ì¹˜ ì ê²€ í•„ìš”'
        })
    
    return alerts

def add_outage_incident(location, business_name, contact, cause, equipment_count, priority):
    """ì‹¤ì‹œê°„ ì •ì „ì¥ì•  ì¶”ê°€"""
    incident = {
        'id': len(st.session_state.outage_incidents) + 1,
        'timestamp': datetime.now(),
        'location': location,
        'business_name': business_name,
        'contact': contact,
        'cause': cause,
        'equipment_count': equipment_count,
        'priority': priority,
        'status': 'ëŒ€ê¸°ì¤‘',
        'assigned_to': '',
        'resolution_time': None,
        'notes': f'KT í†µì‹ ì¥ë¹„ ì¥ì•  - {cause}',
        'equipment_type': 'KT í†µì‹ ì¥ë¹„'
    }
    st.session_state.outage_incidents.append(incident)
    return incident['id']

def update_incident_status(incident_id, status, assigned_to="", notes=""):
    """ì¥ì•  ìƒíƒœ ì—…ë°ì´íŠ¸"""
    for incident in st.session_state.outage_incidents:
        if incident['id'] == incident_id:
            incident['status'] = status
            incident['assigned_to'] = assigned_to
            incident['notes'] = notes
            if status == 'ë³µêµ¬ì™„ë£Œ':
                incident['resolution_time'] = datetime.now()
            break

# --- ì…ì£¼ë¯¼ ëŒ€ì‘ ë©˜íŠ¸ ê´€ë ¨ í•¨ìˆ˜ë“¤ ---
def generate_resident_message(incident, message_type, estimated_time=""):
    """ì…ì£¼ë¯¼ ëŒ€ì‘ ë©˜íŠ¸ ìƒì„±"""
    template = st.session_state.message_templates[message_type]['template']
    title = st.session_state.message_templates[message_type]['title']
    
    # í…œí”Œë¦¿ ë³€ìˆ˜ ì¹˜í™˜
    message_content = template.format(
        location=incident['location'],
        contact=incident['contact'] or "ë¬¸ì˜ì‚¬í•­ ì—†ìŒ",
        estimated_time=estimated_time or "30ë¶„ ë‚´"
    )
    
    return {
        'id': len(st.session_state.resident_messages) + 1,
        'incident_id': incident['id'],
        'timestamp': datetime.now(),
        'title': title,
        'content': message_content,
        'message_type': message_type,
        'status': 'ìƒì„±ë¨',
        'estimated_time': estimated_time
    }

def add_resident_message(incident, message_type, estimated_time=""):
    """ì…ì£¼ë¯¼ ëŒ€ì‘ ë©˜íŠ¸ ì¶”ê°€"""
    message = generate_resident_message(incident, message_type, estimated_time)
    st.session_state.resident_messages.append(message)
    return message['id']

def get_extended_outage_incidents():
    """30ë¶„ ì´ìƒ ì§€ì†ëœ ì¥ì•  ì¡°íšŒ"""
    current_time = datetime.now()
    extended_incidents = []
    
    for incident in st.session_state.outage_incidents:
        if incident['status'] != 'ë³µêµ¬ì™„ë£Œ':
            duration = current_time - incident['timestamp']
            if duration.total_seconds() > 1800:  # 30ë¶„ = 1800ì´ˆ
                extended_incidents.append(incident)
    
    return extended_incidents

def should_send_extended_message(incident):
    """30ë¶„ ê°„ê²©ìœ¼ë¡œ í™•ì¥ ë©”ì‹œì§€ë¥¼ ë³´ë‚¼ì§€ í™•ì¸"""
    current_time = datetime.now()
    duration = current_time - incident['timestamp']
    
    # 30ë¶„ ê°„ê²©ìœ¼ë¡œ ë©”ì‹œì§€ ì „ì†¡ (30ë¶„, 60ë¶„, 90ë¶„, 120ë¶„...)
    minutes_elapsed = int(duration.total_seconds() / 60)
    return minutes_elapsed > 0 and minutes_elapsed % 30 == 0

# --- ì¥ë¹„ DB ì €ì¥/ë¡œë“œ í•¨ìˆ˜ë“¤ ---
def save_equipment_db(equipment_df, filename="equipment_db.pkl"):
    """ì¥ë¹„ DBë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    try:
        # ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
        data_dir = "data"
        if not os.path.exists(data_dir):
            os.makedirs(data_dir)
        
        filepath = os.path.join(data_dir, filename)
        with open(filepath, 'wb') as f:
            pickle.dump(equipment_df, f)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'upload_time': datetime.now().isoformat(),
            'total_records': len(equipment_df),
            'total_equipment': equipment_df['ì¥ë¹„ìˆ˜'].fillna(0).astype(int).sum(),
            'columns': list(equipment_df.columns)
        }
        
        metadata_path = os.path.join(data_dir, "equipment_db_metadata.json")
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        return True, filepath
    except Exception as e:
        return False, str(e)

def load_equipment_db(filename="equipment_db.pkl"):
    """ì¥ë¹„ DBë¥¼ íŒŒì¼ì—ì„œ ë¡œë“œ"""
    try:
        filepath = os.path.join("data", filename)
        if os.path.exists(filepath):
            with open(filepath, 'rb') as f:
                equipment_df = pickle.load(f)
            return True, equipment_df
        else:
            return False, "íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    except Exception as e:
        return False, str(e)

def get_equipment_db_metadata():
    """ì¥ë¹„ DB ë©”íƒ€ë°ì´í„° ì¡°íšŒ"""
    try:
        metadata_path = os.path.join("data", "equipment_db_metadata.json")
        if os.path.exists(metadata_path):
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            return True, metadata
        else:
            return False, "ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    except Exception as e:
        return False, str(e)

def delete_equipment_db():
    """ì¥ë¹„ DB íŒŒì¼ ì‚­ì œ"""
    try:
        data_dir = "data"
        db_file = os.path.join(data_dir, "equipment_db.pkl")
        metadata_file = os.path.join(data_dir, "equipment_db_metadata.json")
        
        if os.path.exists(db_file):
            os.remove(db_file)
        if os.path.exists(metadata_file):
            os.remove(metadata_file)
        
        return True, "ì¥ë¹„ DBê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."
    except Exception as e:
        return False, str(e)

# --- ë©˜íŠ¸ í…œí”Œë¦¿ ì €ì¥/ë¡œë“œ í•¨ìˆ˜ë“¤ ---
def save_message_templates(templates, filename="message_templates.json"):
    """ë©˜íŠ¸ í…œí”Œë¦¿ì„ íŒŒì¼ë¡œ ì €ì¥"""
    try:
        # ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
        data_dir = "data"
        if not os.path.exists(data_dir):
            os.makedirs(data_dir)
        
        filepath = os.path.join(data_dir, filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(templates, f, ensure_ascii=False, indent=2)
        
        return True, filepath
    except Exception as e:
        return False, str(e)

def load_message_templates(filename="message_templates.json"):
    """ë©˜íŠ¸ í…œí”Œë¦¿ì„ íŒŒì¼ì—ì„œ ë¡œë“œ"""
    try:
        filepath = os.path.join("data", filename)
        if os.path.exists(filepath):
            with open(filepath, 'r', encoding='utf-8') as f:
                templates = json.load(f)
            return True, templates
        else:
            return False, "íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    except Exception as e:
        return False, str(e)

def get_default_message_templates():
    """ê¸°ë³¸ ë©˜íŠ¸ í…œí”Œë¦¿ ë°˜í™˜"""
    return {
        'power_outage': {
            'title': 'KT í†µì‹ ì¥ë¹„ ê³µìš©ë¶€ ì •ì „ ë°œìƒ ì•ˆë‚´',
            'template': '[{location}] ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ. ê´€ë¦¬ì‚¬ë¬´ì†Œì…ë‹ˆë‹¤. í˜„ì¬ ê³µìš©ë¶€ ì •ì „ìœ¼ë¡œ ì¸í•´ í†µì‹ ì¥ë¹„ ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¶ˆí¸ì„ ë“œë¦¬ê³  ìˆìŠµë‹ˆë‹¤. .\n\ní˜„ì¬ í•œì „ì—ì„œ ê¸´ê¸‰ ë³µêµ¬ ì‘ì—…ì„ ì§„í–‰ ì¤‘ì´ë©°, ë¹ ë¥¸ ì‹œê°„ ë‚´ì— ì •ìƒí™”í•˜ê² ìŠµë‹ˆë‹¤.\n\ní†µì‹  ì„œë¹„ìŠ¤ ì´ìš©ì— ë¶ˆí¸ì„ ë¼ì³ ëŒ€ë‹¨íˆ ì£„ì†¡í•©ë‹ˆë‹¤.\n\në¬¸ì˜ì‚¬í•­: {contact}'
        },
        'line_fault': {
            'title': 'KT í†µì‹ ì¥ë¹„ íšŒì„ /ì„ ë¡œ ì¥ì•  ë°œìƒ ì•ˆë‚´',
            'template': '[{location}] KT í†µì‹ ì¥ë¹„ íšŒì„ /ì„ ë¡œ ì¥ì• ê°€ ë°œìƒí•˜ì—¬  ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\ní˜„ì¬ í†µì‹ íšŒì„  ì¥ì• ë¡œ ì¸í„°ë„·, ìœ ì„ ì „í™”, IPTV ì„œë¹„ìŠ¤ ì´ìš©ì— ë¶ˆí¸ì„ ë“œë¦¬ê³  ìˆìŠµë‹ˆë‹¤. ktì— ë³µêµ¬íŒ€ì´ ì¶œë™í•˜ì—¬ ì‘ì—…ì„ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë¹ ë¥¸ ì‹œê°„ë‚´ ì •ìƒí™”ë  ì˜ˆì •ì´ë‹ˆ ì–‘í•´ ë¶€íƒë“œë¦½ë‹ˆë‹¤."\n\nì„œë¹„ìŠ¤ ì´ìš©ì— ë¶ˆí¸ì„ ë“œë ¤ ì£„ì†¡í•©ë‹ˆë‹¤.\n\në¬¸ì˜ì‚¬í•­: {contact}'
        },
        'extended_outage': {
            'title': 'KT í†µì‹ ì¥ë¹„ ì¥ì•  ì§€ì† ì•ˆë‚´ (30ë¶„ ê°„ê²©)',
            'template': '[{location}] KT í†µì‹ ì¥ë¹„ ì¥ì•  ìƒí™©ì´ ì§€ì†ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n\ní˜„ì¬ KT ê¸°ìˆ ì§„ì´ ë³µêµ¬ ì‘ì—…ì„ ìµœëŒ€í•œ ì‹ ì†í•˜ê²Œ ì§„í–‰ ì¤‘ì´ë©°, ì˜ˆìƒ ë³µêµ¬ ì‹œê°„ì€ ì•½ {estimated_time}ì…ë‹ˆë‹¤.\n\nì§€ì†ì ì¸ í†µì‹  ì„œë¹„ìŠ¤ ì¥ì• ë¡œ ë¶ˆí¸ì„ ë¼ì³ ëŒ€ë‹¨íˆ ì£„ì†¡í•©ë‹ˆë‹¤.\n\nì¶”ê°€ ì•ˆë‚´ì‚¬í•­ì´ ìˆìœ¼ë©´ ì¦‰ì‹œ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n\në¬¸ì˜ì‚¬í•­: {contact}'
        }
    }

def save_incident_history(incident_df, filename="incident_history.pkl"):
    """ì¥ì•  ì´ë ¥ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    try:
        # ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
        data_dir = "data"
        if not os.path.exists(data_dir):
            os.makedirs(data_dir)
        
        filepath = os.path.join(data_dir, filename)
        with open(filepath, 'wb') as f:
            pickle.dump(incident_df, f)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'upload_time': datetime.now().isoformat(),
            'total_records': len(incident_df),
            'columns': list(incident_df.columns),
            'date_range': {
                'start': incident_df['ì¥ì• ë°œìƒì‹œê°'].min() if 'ì¥ì• ë°œìƒì‹œê°' in incident_df.columns else 'N/A',
                'end': incident_df['ì¥ì• ë°œìƒì‹œê°'].max() if 'ì¥ì• ë°œìƒì‹œê°' in incident_df.columns else 'N/A'
            }
        }
        
        metadata_path = os.path.join(data_dir, "incident_history_metadata.json")
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        return True, filepath
    except Exception as e:
        return False, str(e)

def load_incident_history(filename="incident_history.pkl"):
    """ì¥ì•  ì´ë ¥ ë°ì´í„°ë¥¼ íŒŒì¼ì—ì„œ ë¡œë“œ"""
    try:
        filepath = os.path.join("data", filename)
        if os.path.exists(filepath):
            with open(filepath, 'rb') as f:
                incident_df = pickle.load(f)
            return True, incident_df
        else:
            return False, "íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    except Exception as e:
        return False, str(e)

def get_incident_history_metadata():
    """ì¥ì•  ì´ë ¥ ë©”íƒ€ë°ì´í„° ì¡°íšŒ"""
    try:
        metadata_path = os.path.join("data", "incident_history_metadata.json")
        if os.path.exists(metadata_path):
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            return True, metadata
        else:
            return False, "ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    except Exception as e:
        return False, str(e)

def analyze_incident_patterns(incident_df, business_name=None):
    """ì¥ì•  íŒ¨í„´ ë¶„ì„"""
    if incident_df is None or len(incident_df) == 0:
        return None
    
    # ë°ì´í„° ì „ì²˜ë¦¬
    df = incident_df.copy()
    
    # ì¥ì• ë°œìƒì‹œê°ì„ datetimeìœ¼ë¡œ ë³€í™˜
    if 'ì¥ì• ë°œìƒì‹œê°' in df.columns:
        try:
            df['ì¥ì• ë°œìƒì‹œê°'] = pd.to_datetime(df['ì¥ì• ë°œìƒì‹œê°'], errors='coerce')
            df = df.dropna(subset=['ì¥ì• ë°œìƒì‹œê°'])
        except:
            pass
    
    # íŠ¹ì • ì‚¬ì—…ì¥ í•„í„°ë§
    if business_name and 'ì‚¬ì—…ì¥ëª…' in df.columns:
        df = df[df['ì‚¬ì—…ì¥ëª…'].str.contains(business_name, na=False, case=False)]
    
    if len(df) == 0:
        return None
    
    analysis = {
        'total_incidents': len(df),
        'business_name': business_name,
        'date_range': {
            'start': df['ì¥ì• ë°œìƒì‹œê°'].min() if 'ì¥ì• ë°œìƒì‹œê°' in df.columns else 'N/A',
            'end': df['ì¥ì• ë°œìƒì‹œê°'].max() if 'ì¥ì• ë°œìƒì‹œê°' in df.columns else 'N/A'
        },
        'patterns': {}
    }
    
    # ì¥ë¹„êµ¬ë¶„ë³„ ë¶„ì„
    if 'ì¥ë¹„êµ¬ë¶„' in df.columns:
        equipment_stats = df['ì¥ë¹„êµ¬ë¶„'].value_counts()
        analysis['patterns']['equipment'] = equipment_stats.to_dict()
    
    # ì¥ì• ë¶„ë¥˜ë³„ ë¶„ì„
    if 'ì¥ì• ë¶„ë¥˜' in df.columns:
        category_stats = df['ì¥ì• ë¶„ë¥˜'].value_counts()
        analysis['patterns']['category'] = category_stats.to_dict()
    
    # ì›ì¸ë³„ ë¶„ì„
    if 'ì›ì¸' in df.columns:
        cause_stats = df['ì›ì¸'].value_counts()
        analysis['patterns']['cause'] = cause_stats.to_dict()
    
    # ì§€ì—­ë³„ ë¶„ì„
    if 'ì§€ì—­' in df.columns:
        region_stats = df['ì§€ì—­'].value_counts()
        analysis['patterns']['region'] = region_stats.to_dict()
    
    # ì›”ë³„/ê³„ì ˆë³„/ìš°ê¸°ì²  ë¶„ì„
    if 'ì¥ì• ë°œìƒì‹œê°' in df.columns:
        df['month'] = df['ì¥ì• ë°œìƒì‹œê°'].dt.month
        df['season'] = df['ì¥ì• ë°œìƒì‹œê°'].dt.month.map({
            12: 'ê²¨ìš¸', 1: 'ê²¨ìš¸', 2: 'ê²¨ìš¸',
            3: 'ë´„', 4: 'ë´„', 5: 'ë´„',
            6: 'ì—¬ë¦„', 7: 'ì—¬ë¦„', 8: 'ì—¬ë¦„',
            9: 'ê°€ì„', 10: 'ê°€ì„', 11: 'ê°€ì„'
        })
        
        # ìš°ê¸°ì²  ë¶„ì„ (6ì›”~9ì›”)
        df['is_rainy_season'] = df['month'].isin([6, 7, 8, 9])
        rainy_season_df = df[df['is_rainy_season'] == True]
        
        month_stats = df['month'].value_counts().sort_index()
        season_stats = df['season'].value_counts()
        
        analysis['patterns']['monthly'] = month_stats.to_dict()
        analysis['patterns']['seasonal'] = season_stats.to_dict()
        
        # ìš°ê¸°ì²  ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        if len(rainy_season_df) > 0:
            analysis['patterns']['rainy_season'] = {
                'total_incidents': len(rainy_season_df),
                'percentage': round(len(rainy_season_df) / len(df) * 100, 1)
            }
            
            # ìš°ê¸°ì²  ì£¼ìš” ì¥ì•  ì›ì¸ Top3
            if 'ì›ì¸' in rainy_season_df.columns:
                rainy_causes = rainy_season_df['ì›ì¸'].value_counts().head(3)
                analysis['patterns']['rainy_causes'] = rainy_causes.to_dict()
            
            # ìš°ê¸°ì²  ì£¼ìš” ì¥ì•  ë¶„ë¥˜ Top3
            if 'ì¥ì• ë¶„ë¥˜' in rainy_season_df.columns:
                rainy_categories = rainy_season_df['ì¥ì• ë¶„ë¥˜'].value_counts().head(3)
                analysis['patterns']['rainy_categories'] = rainy_categories.to_dict()
    
    return analysis

def predict_incident_risk(analysis, business_name):
    """ì¥ì•  ìœ„í—˜ë„ ì˜ˆì¸¡ (ë‹¨ìˆœ íšŸìˆ˜ ê¸°ì¤€)"""
    if not analysis or analysis['total_incidents'] == 0:
        return {
            'risk_level': 'ë‚®ìŒ',
            'confidence': 0,
            'reasons': ['ê³¼ê±° ì¥ì•  ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤.']
        }
    total_incidents = analysis['total_incidents']
    reasons = []
    # ë‹¨ìˆœ íšŸìˆ˜ ê¸°ì¤€
    if total_incidents >= 6:
        risk_score = 40
        risk_level = 'ë†’ìŒ'
        reasons.append(f"ê³¼ê±° ì¥ì•  ë°œìƒ ë¹ˆë„ ë†’ìŒ ({total_incidents}íšŒ)")
    elif total_incidents == 5:
        risk_score = 20
        risk_level = 'ë³´í†µ'
        reasons.append(f"ê³¼ê±° ì¥ì•  ë°œìƒ ë¹ˆë„ ë³´í†µ (5íšŒ)")
    else:
        risk_score = 0
        risk_level = 'ë‚®ìŒ'
        reasons.append(f"ê³¼ê±° ì¥ì•  ë°œìƒ ë¹ˆë„ ë‚®ìŒ ({total_incidents}íšŒ)")
    confidence = min(90, 50 + (total_incidents * 5))
    return {
        'risk_level': risk_level,
        'risk_score': risk_score,
        'confidence': confidence,
        'reasons': reasons,
        'recommendations': generate_recommendations(analysis, risk_level)
    }

def generate_recommendations(analysis, risk_level):
    """ì¥ì•  ì˜ˆë°© ê¶Œì¥ì‚¬í•­ ìƒì„±"""
    recommendations = []
    
    if risk_level in ['ë†’ìŒ', 'ë§¤ìš° ë†’ìŒ']:
        recommendations.append("ğŸ” ì •ê¸° ì ê²€ ì£¼ê¸° ë‹¨ì¶• (ì›” 1íšŒ â†’ ì›” 2íšŒ)")
        recommendations.append("ğŸ“Š ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•")
        recommendations.append("ğŸ› ï¸ ì˜ˆë°© ì •ë¹„ ê³„íš ìˆ˜ë¦½")
    
    if 'cause' in analysis['patterns']:
        causes = analysis['patterns']['cause']
        if 'ì„¤ë¹„ ë…¸í›„í™”' in causes:
            recommendations.append("âš¡ ì„¤ë¹„ êµì²´ ê³„íš ìˆ˜ë¦½")
        if 'ì „ì› ê³µê¸‰ ë¶ˆì•ˆì •' in causes:
            recommendations.append("ğŸ”Œ UPS ì‹œìŠ¤í…œ ì ê²€ ë° ë³´ê°•")
        if 'ì¼€ì´ë¸” ì†ìƒ' in causes:
            recommendations.append("ğŸ”— ì¼€ì´ë¸” ìƒíƒœ ì ê²€ ë° ë³´í˜¸ì¥ì¹˜ ì„¤ì¹˜")
    
    if 'seasonal' in analysis['patterns']:
        seasons = analysis['patterns']['seasonal']
        if 'ì—¬ë¦„' in seasons and seasons['ì—¬ë¦„'] >= 2:
            recommendations.append("âš¡ ì„œì§€ ë³´í˜¸ì¥ì¹˜ ì ê²€ ë° ë³´ê°•")
        if 'ê²¨ìš¸' in seasons and seasons['ê²¨ìš¸'] >= 2:
            recommendations.append("â„ï¸ ë°©í•œ ì„¤ë¹„ ì ê²€ ë° ë³´ê°•")
    
    if not recommendations:
        recommendations.append("âœ… í˜„ì¬ ìƒíƒœ ìœ ì§€ (ì •ê¸° ì ê²€ ê³„ì†)")
    
    return recommendations

def generate_rainy_season_recommendations(rainy_causes):
    """ìš°ê¸°ì²  ì¥ì•  ì˜ˆë°©ì ê²€ í™œë™ ì œì•ˆ"""
    recommendations = []
    
    if not rainy_causes:
        return ["ìš°ê¸°ì²  ì¥ì•  ì´ë ¥ì´ ì—†ì–´ êµ¬ì²´ì ì¸ ê¶Œì¥ì‚¬í•­ì„ ì œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
    
    # ìš°ê¸°ì²  ì£¼ìš” ì¥ì•  ì›ì¸ë³„ ì˜ˆë°©ì ê²€ í™œë™
    cause_recommendations = {
        'ìŠµê¸°': [
            "ë°©ìˆ˜/ë°©ìŠµ ì‹œì„¤ ì ê²€ ë° ë³´ì™„",
            "ìŠµê¸° ê°ì§€ ì„¼ì„œ ì„¤ì¹˜ ë° ëª¨ë‹ˆí„°ë§",
            "ì •ê¸°ì ì¸ ìŠµë„ ì¸¡ì • ë° ê¸°ë¡"
        ],
        'ëˆ„ìˆ˜': [
            "ì§€ë¶• ë° ë°°ê´€ ëˆ„ìˆ˜ ì ê²€",
            "ë°©ìˆ˜ì¬ ë³´ìˆ˜ ë° êµì²´",
            "ë°°ìˆ˜ ì‹œìŠ¤í…œ ì •ê¸° ì ê²€"
        ],
        'ë²ˆê°œ': [
            "í”¼ë¢°ì¹¨ ì„¤ì¹˜ ìƒíƒœ ì ê²€",
            "ì„œì§€ ë³´í˜¸ê¸°(SPD) ì ê²€ ë° êµì²´",
            "ì ‘ì§€ ì‹œìŠ¤í…œ ì •ê¸° ì¸¡ì •"
        ],
        'ê°•ìš°': [
            "ì§€ë¶• ë° ì™¸ë²½ ë°©ìˆ˜ ìƒíƒœ ì ê²€",
            "ë°°ìˆ˜ë¡œ ë° í•˜ìˆ˜êµ¬ ì •ê¸° ì •ë¦¬",
            "ë¹„ìƒ ë°°ìˆ˜ íŒí”„ ì ê²€"
        ],
        'ìŠµë„': [
            "ì œìŠµê¸° ì„¤ì¹˜ ë° ìš´ì˜",
            "í™˜ê¸° ì‹œìŠ¤í…œ ì ê²€",
            "ìŠµë„ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•"
        ]
    }
    
    # ì£¼ìš” ì›ì¸ë³„ ê¶Œì¥ì‚¬í•­ ì¶”ê°€
    for cause, count in rainy_causes.items():
        if cause in cause_recommendations:
            recommendations.extend(cause_recommendations[cause])
        else:
            # ì¼ë°˜ì ì¸ ìš°ê¸°ì²  ì˜ˆë°©ì ê²€
            recommendations.extend([
                "ìš°ê¸°ì²  ì „ ë°©ìˆ˜/ë°©ìŠµ ì‹œì„¤ ì¢…í•© ì ê²€",
                "ë¹„ìƒ ì „ì› ì‹œìŠ¤í…œ ì ê²€",
                "í†µì‹ ì„ ë¡œ ë³´í˜¸ ì‹œì„¤ ì ê²€"
            ])
    
    # ì¤‘ë³µ ì œê±° ë° ìƒìœ„ 5ê°œë§Œ ë°˜í™˜
    unique_recommendations = list(dict.fromkeys(recommendations))
    return unique_recommendations[:5]

def analyze_rainy_season_businesses(incident_df, team_name=None):
    """ìš°ê¸°ì² (6ì›”~9ì›”) ì¥ì•  ì§‘ì¤‘ë°œìƒ ì‚¬ì—…ì¥ ë¶„ì„"""
    if incident_df.empty or 'ì¥ì• ë°œìƒì‹œê°' not in incident_df.columns:
        return None
    
    # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
    df = incident_df.copy()
    df['ì¥ì• ë°œìƒì‹œê°'] = pd.to_datetime(df['ì¥ì• ë°œìƒì‹œê°'], errors='coerce')
    df = df.dropna(subset=['ì¥ì• ë°œìƒì‹œê°'])
    
    # íŒ€ í•„í„°ë§
    if team_name and team_name != 'ì „ì²´':
        df = df[df['ìš´ìš©íŒ€'] == team_name]
    
    # ìš°ê¸°ì²  í•„í„°ë§ (6ì›”~9ì›”)
    df['month'] = df['ì¥ì• ë°œìƒì‹œê°'].dt.month
    rainy_df = df[df['month'].isin([6, 7, 8, 9])]
    
    if rainy_df.empty:
        return None
    
    # ì‚¬ì—…ì¥ë³„ ìš°ê¸°ì²  ì¥ì•  ë¶„ì„
    business_analysis = rainy_df.groupby('ì‚¬ì—…ì¥ëª…').agg({
        'ì¥ì• ë°œìƒì‹œê°': 'count',
        'ì›ì¸': lambda x: x.value_counts().to_dict(),
        'ì¥ì• ë¶„ë¥˜': lambda x: x.value_counts().to_dict()
    }).rename(columns={'ì¥ì• ë°œìƒì‹œê°': 'ìš°ê¸°ì² _ì¥ì• ê±´ìˆ˜'}).reset_index()
    
    # ìš°ê¸°ì²  ì¥ì• ê°€ 2ê±´ ì´ìƒì¸ ì‚¬ì—…ì¥ë§Œ ì„ ë³„
    high_risk_businesses = business_analysis[business_analysis['ìš°ê¸°ì² _ì¥ì• ê±´ìˆ˜'] >= 2].copy()
    
    # ìš°ì„ ìˆœìœ„ ê³„ì‚° (ì¥ì• ê±´ìˆ˜ + ì£¼ìš”ì›ì¸ ìœ„í—˜ë„)
    def calculate_priority(row):
        priority_score = row['ìš°ê¸°ì² _ì¥ì• ê±´ìˆ˜'] * 10
        
        # ì£¼ìš” ì›ì¸ë³„ ìœ„í—˜ë„ ê°€ì¤‘ì¹˜
        causes = row['ì›ì¸']
        if causes:
            for cause, count in causes.items():
                if 'ì •ì „' in cause or 'ì „ì›' in cause:
                    priority_score += count * 5
                elif 'ì¼€ì´ë¸”' in cause or 'ì„ ë¡œ' in cause:
                    priority_score += count * 4
                elif 'ì¥ë¹„' in cause or 'ì„¤ë¹„' in cause:
                    priority_score += count * 3
                else:
                    priority_score += count * 2
        
        return priority_score
    
    high_risk_businesses['ìš°ì„ ìˆœìœ„ì ìˆ˜'] = high_risk_businesses.apply(calculate_priority, axis=1)
    high_risk_businesses = high_risk_businesses.sort_values('ìš°ì„ ìˆœìœ„ì ìˆ˜', ascending=False)
    
    # ì„ ì œì  ì ê²€ ê¶Œì¥ì‚¬í•­ ìƒì„±
    def generate_preventive_actions(row):
        actions = []
        causes = row['ì›ì¸']
        
        if causes:
            for cause, count in causes.items():
                if 'ì •ì „' in cause or 'ì „ì›' in cause:
                    actions.append(f"âš¡ ì‚¬ì—…ì¥ ì „ì›ì‹œì„¤ ì ê²€ ({count}íšŒ ë°œìƒ)")
                elif 'ì¼€ì´ë¸”' in cause or 'ì„ ë¡œ' in cause:
                    actions.append(f"ğŸ”Œ ì¼€ì´ë¸” í”¼ë³µ/ëˆ„ìˆ˜ ì ê²€ ({count}íšŒ ë°œìƒ)")
                elif 'ì¥ë¹„' in cause or 'ì„¤ë¹„' in cause:
                    actions.append(f"ğŸ”§ ì¥ë¹„ ìŠµê¸°/í™˜ê¸° ì ê²€ ({count}íšŒ ë°œìƒ)")
                else:
                    actions.append(f"ğŸ” ì¢…í•© ì ê²€ ({count}íšŒ ë°œìƒ)")
        
        return actions
    
    high_risk_businesses['ì„ ì œì _ì ê²€ì‚¬í•­'] = high_risk_businesses.apply(generate_preventive_actions, axis=1)
    
    return high_risk_businesses

# --- ë¹…ë°ì´í„° ì¥ì• ì´ë ¥ë¶„ì„ í•¨ìˆ˜ë“¤ ---
def create_incident_trend_chart(incident_df, business_name=None):
    """ì¥ì•  ë°œìƒ ì¶”ì´ ì°¨íŠ¸ ìƒì„± (70ê±´ ì´ìƒ ë°œìƒì¼ì— ì£¼ìš” ì›ì¸ ë§ˆì»¤ í‘œì‹œ)"""
    if incident_df is None or len(incident_df) == 0:
        return None
    df = incident_df.copy()
    # íŠ¹ì • ì‚¬ì—…ì¥ í•„í„°ë§
    if business_name and 'ì‚¬ì—…ì¥ëª…' in df.columns:
        df = df[df['ì‚¬ì—…ì¥ëª…'].str.contains(business_name, na=False, case=False)]
    if len(df) == 0:
        return None
    # ë‚ ì§œë³„ ì¥ì•  ë°œìƒ ìˆ˜ ì§‘ê³„
    if 'ì¥ì• ë°œìƒì‹œê°' in df.columns:
        df['ì¥ì• ë°œìƒì‹œê°'] = pd.to_datetime(df['ì¥ì• ë°œìƒì‹œê°'], errors='coerce')
        df = df.dropna(subset=['ì¥ì• ë°œìƒì‹œê°'])
        df['date'] = df['ì¥ì• ë°œìƒì‹œê°'].dt.date
        daily_incidents = df.groupby('date').size().reset_index(name='incident_count')
        daily_incidents['date'] = pd.to_datetime(daily_incidents['date'])
        # 7ì¼ ì´ë™í‰ê·  ê³„ì‚°
        daily_incidents['moving_avg'] = daily_incidents['incident_count'].rolling(window=7, min_periods=1).mean()
        
        # í‰ê· ê°’ ê³„ì‚° (ì „ì²´ ê¸°ê°„)
        total_avg = daily_incidents['incident_count'].mean()
        
        fig = go.Figure()
        
        # ì‹¤ì œ ì¥ì•  ë°œìƒ ìˆ˜
        fig.add_trace(go.Scatter(
            x=daily_incidents['date'],
            y=daily_incidents['incident_count'],
            mode='markers+lines',
            name='ì¼ì¼ ì¥ì•  ë°œìƒ',
            line=dict(color='#ff6b6b', width=2),
            marker=dict(size=6, color='#ff6b6b'),
            hovertemplate='ë‚ ì§œ: %{x}<br>ì¥ì•  ë°œìƒ: %{y}ê±´<extra></extra>'
        ))
        
        # 7ì¼ ì´ë™í‰ê· ì„ 
        fig.add_trace(go.Scatter(
            x=daily_incidents['date'],
            y=daily_incidents['moving_avg'],
            mode='lines',
            name='7ì¼ ì´ë™í‰ê· ',
            line=dict(color='#4ecdc4', width=3, dash='dash'),
            hovertemplate='ë‚ ì§œ: %{x}<br>7ì¼ í‰ê· : %{y:.1f}ê±´<extra></extra>'
        ))
        
        # ì „ì²´ ê¸°ê°„ í‰ê· ì„ 
        fig.add_hline(
            y=total_avg,
            line_dash="dot",
            line_color="gray",
            annotation_text=f"ì „ì²´ í‰ê· : {total_avg:.1f}ê±´",
            annotation_position="top right"
        )
        # 70ê±´ ì´ìƒ ë°œìƒì¼ì— ì£¼ìš” ì›ì¸ ë§ˆì»¤ í‘œì‹œ
        outlier_dates = daily_incidents[daily_incidents['incident_count'] >= 70]['date']
        for date in outlier_dates:
            day_df = df[df['date'] == date.date()]
            if 'ì›ì¸' in day_df.columns and not day_df['ì›ì¸'].isnull().all():
                top_cause = day_df['ì›ì¸'].value_counts().idxmax()
                fig.add_trace(go.Scatter(
                    x=[date],
                    y=[day_df.shape[0]],
                    mode='markers+text',
                    marker=dict(size=16, color='orange', symbol='star'),
                    text=[f"{top_cause}"],
                    textposition="top center",
                    name=f"ì´ìƒì¹˜({date.strftime('%Y-%m-%d')})"
                ))
        fig.update_layout(
            title=f"ğŸ“ˆ {'ì „ì²´' if business_name is None else business_name} L2 SW ì¥ì•  ë°œìƒ ì¶”ì´ (7ì¼ í‰ê·  í¬í•¨)",
            xaxis_title="ë‚ ì§œ",
            yaxis_title="ì¥ì•  ë°œìƒ ìˆ˜",
            hovermode='x unified',
            template='plotly_white',
            height=400,
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="right",
                x=1
            )
        )
        return fig
    return None

def create_equipment_category_chart(incident_df, business_name=None):
    """ì¥ë¹„êµ¬ë¶„ë³„ ì¥ì•  ë¶„ì„ ì°¨íŠ¸"""
    if incident_df is None or len(incident_df) == 0:
        return None
    
    df = incident_df.copy()
    
    # íŠ¹ì • ì‚¬ì—…ì¥ í•„í„°ë§
    if business_name and 'ì‚¬ì—…ì¥ëª…' in df.columns:
        df = df[df['ì‚¬ì—…ì¥ëª…'].str.contains(business_name, na=False, case=False)]
    
    if len(df) == 0 or 'ì¥ë¹„êµ¬ë¶„' not in df.columns:
        return None
    
    equipment_stats = df['ì¥ë¹„êµ¬ë¶„'].value_counts()
    
    fig = go.Figure(data=[go.Pie(
        labels=equipment_stats.index,
        values=equipment_stats.values,
        hole=0.4,
        marker_colors=px.colors.qualitative.Set3
    )])
    
    fig.update_layout(
        title=f"âš™ï¸ {'ì „ì²´' if business_name is None else business_name} L2 SW ì¥ë¹„êµ¬ë¶„ë³„ ì¥ì•  ë¶„í¬",
        template='plotly_white',
        height=400
    )
    
    return fig

def create_cause_analysis_chart(incident_df, business_name=None):
    """ì›ì¸ë³„ ì¥ì•  ë¶„ì„ ì°¨íŠ¸ + ì¶œë™/ë¯¸ì¶œë™ êµ¬ë¶„ í‘œ"""
    import streamlit as st
    if incident_df is None or len(incident_df) == 0:
        return None
    
    df = incident_df.copy()
    
    # íŠ¹ì • ì‚¬ì—…ì¥ í•„í„°ë§
    if business_name and 'ì‚¬ì—…ì¥ëª…' in df.columns:
        df = df[df['ì‚¬ì—…ì¥ëª…'].str.contains(business_name, na=False, case=False)]
    
    if len(df) == 0 or 'ì›ì¸' not in df.columns:
        return None
    
    cause_stats = df['ì›ì¸'].value_counts().head(10)
    
    fig = go.Figure(data=[go.Bar(
        x=cause_stats.values,
        y=cause_stats.index,
        orientation='h',
        marker_color='#ff6b6b'
    )])
    
    fig.update_layout(
        title=f"ğŸ¯ {'ì „ì²´' if business_name is None else business_name} L2 SW ì¥ì•  ì›ì¸ ë¶„ì„ (ìƒìœ„ 10ê°œ)",
        xaxis_title="ë°œìƒ íšŸìˆ˜",
        yaxis_title="ì¥ì•  ì›ì¸",
        template='plotly_white',
        height=400
    )
    
    # ì¶œë™/ë¯¸ì¶œë™ êµ¬ë¶„ í‘œ ìƒì„±
    if 'ì¶œë™êµ¬ë¶„' in df.columns:
        top_causes = cause_stats.index.tolist()
        
        # ì›ì¸ë³„ ì¶œë™/ë¯¸ì¶œë™ í†µê³„ ê³„ì‚°
        cause_dispatch_stats = []
        for cause in top_causes:
            cause_data = df[df['ì›ì¸'] == cause]
            dispatch_count = len(cause_data[cause_data['ì¶œë™êµ¬ë¶„'] == 'ì¶œë™'])
            no_dispatch_count = len(cause_data[cause_data['ì¶œë™êµ¬ë¶„'] == 'ë¯¸ì¶œë™'])
            total_count = len(cause_data)
            
            cause_dispatch_stats.append({
                'ì›ì¸': cause,
                'ì¶œë™': dispatch_count,
                'ë¯¸ì¶œë™': no_dispatch_count,
                'ì´ê³„': total_count
            })
        
        # DataFrameìœ¼ë¡œ ë³€í™˜
        stats_df = pd.DataFrame(cause_dispatch_stats)
        
        # í‘œ ìŠ¤íƒ€ì¼ë§ì„ ìœ„í•œ CSS ì¶”ê°€
        st.markdown("""
        <style>
        .compact-table {
            font-size: 12px;
            width: 100%;
            max-width: 600px;
        }
        .compact-table th {
            padding: 8px 12px;
            text-align: center;
            background-color: #f0f2f6;
            font-weight: bold;
            border: 1px solid #ddd;
        }
        .compact-table td {
            padding: 6px 10px;
            text-align: center;
            border: 1px solid #ddd;
        }
        .cause-row {
            background-color: #f8f9fa;
            font-weight: bold;
        }
        </style>
        """, unsafe_allow_html=True)
        
        st.write('#### ì¶œë™/ë¯¸ì¶œë™ë³„ ì¥ì•  ì›ì¸ ìƒìœ„ 10ê°œ')
        
        # í‘œë¥¼ HTMLë¡œ ë Œë”ë§í•˜ì—¬ ë” ì»´íŒ©íŠ¸í•˜ê²Œ í‘œì‹œ
        html_table = stats_df.to_html(classes='compact-table', index=False, escape=False)
        st.markdown(html_table, unsafe_allow_html=True)
    
    return fig

def create_seasonal_pattern_chart(incident_df, business_name=None):
    """ê³„ì ˆë³„ íŒ¨í„´ ë¶„ì„ ì°¨íŠ¸"""
    if incident_df is None or len(incident_df) == 0:
        return None
    
    df = incident_df.copy()
    
    # íŠ¹ì • ì‚¬ì—…ì¥ í•„í„°ë§
    if business_name and 'ì‚¬ì—…ì¥ëª…' in df.columns:
        df = df[df['ì‚¬ì—…ì¥ëª…'].str.contains(business_name, na=False, case=False)]
    
    if len(df) == 0 or 'ì¥ì• ë°œìƒì‹œê°' not in df.columns:
        return None
    
    df['ì¥ì• ë°œìƒì‹œê°'] = pd.to_datetime(df['ì¥ì• ë°œìƒì‹œê°'], errors='coerce')
    df = df.dropna(subset=['ì¥ì• ë°œìƒì‹œê°'])
    
    df['month'] = df['ì¥ì• ë°œìƒì‹œê°'].dt.month
    df['season'] = df['ì¥ì• ë°œìƒì‹œê°'].dt.month.map({
        12: 'ê²¨ìš¸', 1: 'ê²¨ìš¸', 2: 'ê²¨ìš¸',
        3: 'ë´„', 4: 'ë´„', 5: 'ë´„',
        6: 'ì—¬ë¦„', 7: 'ì—¬ë¦„', 8: 'ì—¬ë¦„',
        9: 'ê°€ì„', 10: 'ê°€ì„', 11: 'ê°€ì„'
    })
    
    # ì›”ë³„ ë¶„ì„
    monthly_stats = df['month'].value_counts().sort_index()
    season_stats = df['season'].value_counts()
    
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=('ì›”ë³„ ì¥ì•  ë°œìƒ', 'ê³„ì ˆë³„ ì¥ì•  ë°œìƒ'),
        specs=[[{"type": "bar"}, {"type": "pie"}]]
    )
    
    # ì›”ë³„ ë§‰ëŒ€ ê·¸ë˜í”„
    fig.add_trace(
        go.Bar(x=monthly_stats.index, y=monthly_stats.values, name="ì›”ë³„", marker_color='#4ecdc4'),
        row=1, col=1
    )
    
    # ê³„ì ˆë³„ íŒŒì´ ì°¨íŠ¸
    fig.add_trace(
        go.Pie(labels=season_stats.index, values=season_stats.values, name="ê³„ì ˆë³„"),
        row=1, col=2
    )
    
    fig.update_layout(
        title=f"ğŸŒ¤ï¸ {'ì „ì²´' if business_name is None else business_name} L2 SW ê³„ì ˆë³„ ì¥ì•  íŒ¨í„´",
        template='plotly_white',
        height=400
    )
    
    return fig

def create_region_heatmap(incident_df):
    """ì§€ì—­ë³„ ì¥ì•  ë°œìƒ íˆíŠ¸ë§µ"""
    if incident_df is None or len(incident_df) == 0 or 'ì§€ì—­' not in incident_df.columns:
        return None
    
    df = incident_df.copy()
    
    # ì§€ì—­ë³„ ì¥ì•  ë°œìƒ ìˆ˜ ì§‘ê³„
    region_stats = df['ì§€ì—­'].value_counts()
    
    # ì§€ì—­ë³„ ìœ„í—˜ë„ ê³„ì‚° (ë°œìƒ ë¹ˆë„ ê¸°ë°˜)
    max_incidents = region_stats.max()
    region_stats_normalized = (region_stats / max_incidents * 100).round(1)
    
    fig = go.Figure(data=go.Bar(
        x=region_stats.index,
        y=region_stats.values,
        marker=dict(
            color=region_stats.values,
            colorscale='Reds',
            showscale=True,
            colorbar=dict(title="ì¥ì•  ë°œìƒ ìˆ˜")
        ),
        text=region_stats.values,
        textposition='auto'
    ))
    
    fig.update_layout(
        title="ğŸ—ºï¸ ì§€ì—­ë³„ L2 SW ì¥ì•  ë°œìƒ í˜„í™©",
        xaxis_title="ì§€ì—­",
        yaxis_title="ì¥ì•  ë°œìƒ ìˆ˜",
        template='plotly_white',
        height=400
    )
    
    return fig

def create_maintenance_prediction_chart(incident_df, business_name=None):
    """ì •ë¹„ ì˜ˆì¸¡ ì°¨íŠ¸"""
    if incident_df is None or len(incident_df) == 0:
        return None
    
    df = incident_df.copy()
    
    # íŠ¹ì • ì‚¬ì—…ì¥ í•„í„°ë§
    if business_name and 'ì‚¬ì—…ì¥ëª…' in df.columns:
        df = df[df['ì‚¬ì—…ì¥ëª…'].str.contains(business_name, na=False, case=False)]
    
    if len(df) == 0:
        return None
    
    # ìµœê·¼ 30ì¼ê°„ì˜ ì¥ì•  íŒ¨í„´ ë¶„ì„
    if 'ì¥ì• ë°œìƒì‹œê°' in df.columns:
        df['ì¥ì• ë°œìƒì‹œê°'] = pd.to_datetime(df['ì¥ì• ë°œìƒì‹œê°'], errors='coerce')
        df = df.dropna(subset=['ì¥ì• ë°œìƒì‹œê°'])
        
        # ìµœê·¼ 30ì¼ ë°ì´í„°ë§Œ ì‚¬ìš©
        recent_date = df['ì¥ì• ë°œìƒì‹œê°'].max()
        thirty_days_ago = recent_date - timedelta(days=30)
        recent_df = df[df['ì¥ì• ë°œìƒì‹œê°'] >= thirty_days_ago]
        
        if len(recent_df) > 0:
            # ì¼ë³„ ì¥ì•  ë°œìƒ ìˆ˜
            daily_incidents = recent_df.groupby(recent_df['ì¥ì• ë°œìƒì‹œê°'].dt.date).size()
            
            # ë‹¤ìŒ 7ì¼ ì˜ˆì¸¡ (ê°„ë‹¨í•œ ì„ í˜• ì¶”ì„¸ ê¸°ë°˜)
            if len(daily_incidents) >= 3:
                x = np.arange(len(daily_incidents))
                y = daily_incidents.values
                
                # ì„ í˜• íšŒê·€ë¡œ ì¶”ì„¸ ê³„ì‚°
                coeffs = np.polyfit(x, y, 1)
                trend_line = np.poly1d(coeffs)
                
                # ì˜ˆì¸¡ ë°ì´í„° ìƒì„±
                future_x = np.arange(len(daily_incidents), len(daily_incidents) + 7)
                predictions = trend_line(future_x)
                predictions = np.maximum(predictions, 0)  # ìŒìˆ˜ ë°©ì§€
                
                fig = go.Figure()
                
                # ì‹¤ì œ ë°ì´í„°
                fig.add_trace(go.Scatter(
                    x=list(daily_incidents.index),
                    y=daily_incidents.values,
                    mode='markers+lines',
                    name='ì‹¤ì œ ì¥ì•  ë°œìƒ',
                    line=dict(color='#ff6b6b', width=3),
                    marker=dict(size=8, color='#ff6b6b')
                ))
                
                # ì˜ˆì¸¡ ë°ì´í„°
                future_dates = [recent_date + timedelta(days=i+1) for i in range(7)]
                fig.add_trace(go.Scatter(
                    x=future_dates,
                    y=predictions,
                    mode='markers+lines',
                    name='ì˜ˆì¸¡ ì¥ì•  ë°œìƒ',
                    line=dict(color='#4ecdc4', width=3, dash='dash'),
                    marker=dict(size=8, color='#4ecdc4')
                ))
                
                fig.update_layout(
                    title=f"ğŸ”® {'ì „ì²´' if business_name is None else business_name} L2 SW ì¥ì•  ë°œìƒ ì˜ˆì¸¡ (ë‹¤ìŒ 7ì¼)",
                    xaxis_title="ë‚ ì§œ",
                    yaxis_title="ì˜ˆìƒ ì¥ì•  ë°œìƒ ìˆ˜",
                    template='plotly_white',
                    height=400
                )
                
                return fig
    
    return None

def generate_bigdata_insights(incident_df, business_name=None):
    """ë¹…ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    if incident_df is None or len(incident_df) == 0:
        return []
    
    df = incident_df.copy()
    
    # íŠ¹ì • ì‚¬ì—…ì¥ í•„í„°ë§
    if business_name and 'ì‚¬ì—…ì¥ëª…' in df.columns:
        df = df[df['ì‚¬ì—…ì¥ëª…'].str.contains(business_name, na=False, case=False)]
    
    if len(df) == 0:
        return []
    
    insights = []
    
    # 1. ì¥ì•  ë°œìƒ íŒ¨í„´ ë¶„ì„
    if 'ì¥ì• ë°œìƒì‹œê°' in df.columns:
        df['ì¥ì• ë°œìƒì‹œê°'] = pd.to_datetime(df['ì¥ì• ë°œìƒì‹œê°'], errors='coerce')
        df = df.dropna(subset=['ì¥ì• ë°œìƒì‹œê°'])
        
        # ì‹œê°„ëŒ€ë³„ ë¶„ì„
        df['hour'] = df['ì¥ì• ë°œìƒì‹œê°'].dt.hour
        peak_hour = df['hour'].mode().iloc[0] if len(df['hour'].mode()) > 0 else 0
        insights.append(f"ğŸ• ì¥ì•  ë°œìƒ í”¼í¬ ì‹œê°„ëŒ€: {peak_hour}ì‹œ")
        
        # ìš”ì¼ë³„ ë¶„ì„
        df['weekday'] = df['ì¥ì• ë°œìƒì‹œê°'].dt.day_name()
        peak_day = df['weekday'].mode().iloc[0] if len(df['weekday'].mode()) > 0 else "ì•Œ ìˆ˜ ì—†ìŒ"
        insights.append(f"ğŸ“… ì¥ì•  ë°œìƒ í”¼í¬ ìš”ì¼: {peak_day}")
    
    # 2. ì¥ë¹„ë³„ ë¶„ì„
    if 'ì¥ë¹„êµ¬ë¶„' in df.columns:
        most_frequent_equipment = df['ì¥ë¹„êµ¬ë¶„'].mode().iloc[0] if len(df['ì¥ë¹„êµ¬ë¶„'].mode()) > 0 else "ì•Œ ìˆ˜ ì—†ìŒ"
        insights.append(f"âš™ï¸ ê°€ì¥ ë¹ˆë²ˆí•œ L2 SW ì¥ì•  ì¥ë¹„: {most_frequent_equipment}")
    
    # 3. ì›ì¸ë³„ ë¶„ì„
    if 'ì›ì¸' in df.columns:
        most_common_cause = df['ì›ì¸'].mode().iloc[0] if len(df['ì›ì¸'].mode()) > 0 else "ì•Œ ìˆ˜ ì—†ìŒ"
        insights.append(f"ğŸ¯ ê°€ì¥ ë¹ˆë²ˆí•œ L2 SW ì¥ì•  ì›ì¸: {most_common_cause}")
    
    # 4. ì§€ì—­ë³„ ë¶„ì„
    if 'ì§€ì—­' in df.columns:
        most_affected_region = df['ì§€ì—­'].mode().iloc[0] if len(df['ì§€ì—­'].mode()) > 0 else "ì•Œ ìˆ˜ ì—†ìŒ"
        insights.append(f"ğŸ—ºï¸ ê°€ì¥ ë§ì€ L2 SW ì¥ì•  ë°œìƒ ì§€ì—­: {most_affected_region}")
    
    # 5. ì¶”ì„¸ ë¶„ì„
    if 'ì¥ì• ë°œìƒì‹œê°' in df.columns and len(df) >= 10:
        recent_incidents = df[df['ì¥ì• ë°œìƒì‹œê°'] >= df['ì¥ì• ë°œìƒì‹œê°'].max() - timedelta(days=30)]
        if len(recent_incidents) > len(df) * 0.3:
            insights.append("ğŸ“ˆ ìµœê·¼ 30ì¼ê°„ L2 SW ì¥ì•  ë°œìƒ ë¹ˆë„ ì¦ê°€ ì¶”ì„¸")
        elif len(recent_incidents) < len(df) * 0.1:
            insights.append("ğŸ“‰ ìµœê·¼ 30ì¼ê°„ L2 SW ì¥ì•  ë°œìƒ ë¹ˆë„ ê°ì†Œ ì¶”ì„¸")
        else:
            insights.append("ğŸ“Š ìµœê·¼ 30ì¼ê°„ L2 SW ì¥ì•  ë°œìƒ ë¹ˆë„ ì•ˆì •ì ")
    
    return insights

def create_office_heatmap(incident_df):
    """êµ­ì‚¬ë³„(ì§€ì—­ ê¸°ì¤€) ì¥ì•  ë°œìƒ í˜„í™© íˆíŠ¸ë§µ (ìƒìœ„ 15ê°œë§Œ í‘œì‹œ)"""
    if incident_df is None or len(incident_df) == 0 or 'ì§€ì—­' not in incident_df.columns:
        return None
    df = incident_df.copy()
    # ìƒìœ„ 15ê°œ êµ­ì‚¬ë§Œ í‘œì‹œ
    office_stats = df['ì§€ì—­'].value_counts().head(15)
    max_incidents = office_stats.max()
    office_stats_normalized = (office_stats / max_incidents * 100).round(1)
    fig = go.Figure(data=go.Bar(
        x=office_stats.index,
        y=office_stats.values,
        marker=dict(
            color=office_stats.values,
            colorscale='Blues',
            showscale=True,
            colorbar=dict(title="ì¥ì•  ë°œìƒ ìˆ˜")
        ),
        text=office_stats.values,
        textposition='auto'
    ))
    fig.update_layout(
        title="ğŸ¢ êµ­ì‚¬ë³„ L2 SW ì¥ì•  ë°œìƒ í˜„í™© (ìƒìœ„ 15ê°œ êµ­ì‚¬)",
        xaxis_title="êµ­ì‚¬(ì§€ì—­)",
        yaxis_title="ì¥ì•  ë°œìƒ ìˆ˜",
        template='plotly_white',
        height=400
    )
    return fig

def create_team_heatmap(incident_df):
    """ìš´ìš©íŒ€ë³„ ì¥ì•  ë°œìƒ í˜„í™© íˆíŠ¸ë§µ"""
    if incident_df is None or len(incident_df) == 0 or 'ìš´ìš©íŒ€' not in incident_df.columns:
        return None
    df = incident_df.copy()
    team_stats = df['ìš´ìš©íŒ€'].value_counts()
    max_incidents = team_stats.max()
    team_stats_normalized = (team_stats / max_incidents * 100).round(1)
    fig = go.Figure(data=go.Bar(
        x=team_stats.index,
        y=team_stats.values,
        marker=dict(
            color=team_stats.values,
            colorscale='Greens',
            showscale=True,
            colorbar=dict(title="ì¥ì•  ë°œìƒ ìˆ˜")
        ),
        text=team_stats.values,
        textposition='auto'
    ))
    fig.update_layout(
        title="ğŸ‘¨â€ğŸ’¼ ìš´ìš©íŒ€ë³„ L2 SW ì¥ì•  ë°œìƒ í˜„í™©",
        xaxis_title="ìš´ìš©íŒ€",
        yaxis_title="ì¥ì•  ë°œìƒ ìˆ˜",
        template='plotly_white',
        height=400
    )
    return fig

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if 'outage_incidents' not in st.session_state:
    st.session_state.outage_incidents = []
if 'search_history' not in st.session_state:
    st.session_state.search_history = []
if 'resident_messages' not in st.session_state:
    st.session_state.resident_messages = []
if 'message_templates' not in st.session_state:
    # ì €ì¥ëœ ë©˜íŠ¸ í…œí”Œë¦¿ ìë™ ë¡œë“œ ì‹œë„
    success, result = load_message_templates()
    if success:
        st.session_state.message_templates = result
    else:
        st.session_state.message_templates = get_default_message_templates()


# --- íƒ­ 1: L2 SW ë¹…ë°ì´í„° ëŒ€ì‹œë³´ë“œ ---
with tab1:
    st.header("ğŸ“ˆ L2 SW ë¹…ë°ì´í„° ì¥ì• ì´ë ¥ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    st.markdown("""
    <div style="background-color: #f0f2f6; padding: 20px; border-radius: 10px; margin-bottom: 20px;">
        <h3>ğŸ¯ L2 SW ì¥ì• ì´ë ¥ë¶„ì„ ëŒ€ì‹œë³´ë“œ</h3>
        <p>ì´ ëŒ€ì‹œë³´ë“œëŠ” L2 SWì˜ ì¥ì•  ì´ë ¥ì„ ë¹…ë°ì´í„° ë¶„ì„í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤:</p>
        <ul>
            <li>ğŸ“ˆ <strong>ì¥ì•  ë°œìƒ ì¶”ì´ ë¶„ì„</strong>: ì‹œê°„ë³„, ì¼ë³„, ì›”ë³„ ì¥ì•  ë°œìƒ íŒ¨í„´</li>
            <li>ğŸ¯ <strong>ì›ì¸ë³„ ë¶„ì„</strong>: ì¥ì•  ì›ì¸ë³„ ë°œìƒ ë¹ˆë„ ë° íŒ¨í„´</li>
            <li>ğŸ¢ <strong>êµ­ì‚¬ë³„ ë¶„ì„</strong>: êµ­ì‚¬(ì‚¬ì—…ì¥ëª…)ë³„ ì¥ì•  ë°œìƒ í˜„í™©</li>
            <li>ğŸ‘¨â€ğŸ’¼ <strong>ìš´ìš©íŒ€ë³„ ë¶„ì„</strong>: ìš´ìš©íŒ€ë³„ ì¥ì•  ë°œìƒ í˜„í™©</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

    if 'incident_history' in st.session_state and st.session_state.incident_history is not None:
        subtab1, subtab2 = st.tabs(["ìš”ì•½", "ìƒì„¸ ë¶„ì„"])
        with subtab1:
            # ê¸°ì¡´ ëŒ€ì‹œë³´ë“œ ì „ì²´ ë‚´ìš© ë³µì› (ì•„ë˜ ê¸°ì¡´ ì½”ë“œ ì „ì²´ë¥¼ ë“¤ì—¬ì“°ê¸° í•œ ì¹¸ ì¶”ê°€í•´ì„œ ì´ê³³ì— ë¶™ì—¬ë„£ê¸°)
            # ë¶„ì„ ëª¨ë“œ ì„ íƒ
            col1, col2 = st.columns([3, 1])
            with col1:
                analysis_mode = st.selectbox(
                    "ğŸ” ë¶„ì„ ëª¨ë“œ ì„ íƒ",
                    ["ì „ì²´ L2 SW ë¶„ì„", "íŠ¹ì • ì‚¬ì—…ì¥ ë¶„ì„"],
                    key="dashboard_analysis_mode"
                )
            with col2:
                if analysis_mode == "íŠ¹ì • ì‚¬ì—…ì¥ ë¶„ì„":
                    dashboard_business_search = st.text_input("ğŸ¢ ì‚¬ì—…ì¥ëª…", placeholder="ì˜ˆ: í•´ìš´ëŒ€ ì•„íŒŒíŠ¸, ë¡¯ë°ë°±í™”ì ...", key="dashboard_business_search")
                else:
                    dashboard_business_search = None
            if st.button("ğŸš€ ë¹…ë°ì´í„° ë¶„ì„ ì‹¤í–‰", type="primary", key="dashboard_bigdata_analysis"):
                if analysis_mode == "íŠ¹ì • ì‚¬ì—…ì¥ ë¶„ì„" and not dashboard_business_search:
                    st.warning("ì‚¬ì—…ì¥ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    st.session_state.dashboard_current_business = dashboard_business_search
                    st.success(f"L2 SW {'ì „ì²´' if dashboard_business_search is None else dashboard_business_search} ë¹…ë°ì´í„° ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
                    st.rerun()
            if hasattr(st.session_state, 'dashboard_current_business'):
                business_name = st.session_state.dashboard_current_business
                # ë…„ë„ë³„ ë¶„ì„ í•„í„° ì¶”ê°€
                st.markdown("### ğŸ—“ï¸ ë…„ë„ë³„ ë¶„ì„ ì„¤ì •")
                base_df = st.session_state.incident_history.copy()
                if 'ì¥ì• ë°œìƒì‹œê°' in base_df.columns:
                    base_df['ì¥ì• ë°œìƒì‹œê°'] = pd.to_datetime(base_df['ì¥ì• ë°œìƒì‹œê°'], errors='coerce')
                    base_df = base_df.dropna(subset=['ì¥ì• ë°œìƒì‹œê°'])
                    available_years = sorted(base_df['ì¥ì• ë°œìƒì‹œê°'].dt.year.unique(), reverse=True)
                    if len(available_years) > 1:
                        year_options = ['ì „ì²´ ë…„ë„'] + [str(year) for year in available_years]
                        selected_year = st.selectbox("ë¶„ì„í•  ë…„ë„ë¥¼ ì„ íƒí•˜ì„¸ìš”", options=year_options, key="year_filter")
                        if selected_year != 'ì „ì²´ ë…„ë„':
                            base_df = base_df[base_df['ì¥ì• ë°œìƒì‹œê°'].dt.year == int(selected_year)]
                            st.info(f"ğŸ“… {selected_year}ë…„ ë°ì´í„°ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
                
                st.markdown("### ğŸ“ˆ ì£¼ìš” ì§€í‘œ ëŒ€ì‹œë³´ë“œ")
                df = base_df.copy()
                if business_name:
                    df = df[df['ì‚¬ì—…ì¥ëª…'].str.contains(business_name, na=False, case=False)]
                total_incidents = len(df)
                if 'ì¥ì• ë°œìƒì‹œê°' in df.columns:
                    df['ì¥ì• ë°œìƒì‹œê°'] = pd.to_datetime(df['ì¥ì• ë°œìƒì‹œê°'], errors='coerce')
                    df = df.dropna(subset=['ì¥ì• ë°œìƒì‹œê°'])
                    if not df.empty:
                        date_range = f"{df['ì¥ì• ë°œìƒì‹œê°'].min().strftime('%Y-%m-%d')} ~ {df['ì¥ì• ë°œìƒì‹œê°'].max().strftime('%Y-%m-%d')}"
                    else:
                        date_range = "24.1~25.4"
                else:
                    date_range = "24.1~25.4"
                analysis = analyze_incident_patterns(df, business_name)
                if analysis:
                    risk_prediction = predict_incident_risk(analysis, business_name or "ì „ì²´")
                else:
                    risk_prediction = {'risk_level': 'ë‚®ìŒ', 'confidence': 0}
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ğŸ“Š ì´ L2 SW ì¥ì• ", f"{total_incidents:,}ê±´")
                with col2:
                    st.markdown(f"**ğŸ“… ë¶„ì„ ê¸°ê°„**<br><span style='font-size:16px'>{date_range}</span>", unsafe_allow_html=True)
                with col3:
                    risk_color = {"ë§¤ìš° ë†’ìŒ": "ğŸ”´", "ë†’ìŒ": "ğŸŸ ", "ë³´í†µ": "ğŸŸ¡", "ë‚®ìŒ": "ğŸŸ¢"}
                    st.metric("âš ï¸ ìœ„í—˜ë„", f"{risk_color.get(risk_prediction['risk_level'], 'ğŸŸ¢')} {risk_prediction['risk_level']}")
                with col4:
                    st.metric("ğŸ¯ ì˜ˆì¸¡ ì‹ ë¢°ë„", f"{risk_prediction['confidence']:.0f}%")
                st.markdown("### ğŸ’¡ L2 SW ë¹…ë°ì´í„° ì¸ì‚¬ì´íŠ¸")
                insights = generate_bigdata_insights(df, business_name)
                if insights:
                    col1, col2 = st.columns(2)
                    with col1:
                        for i, insight in enumerate(insights[:len(insights)//2]):
                            st.info(insight)
                    with col2:
                        for i, insight in enumerate(insights[len(insights)//2:]):
                            st.info(insight)
                else:
                    st.info("ë¶„ì„í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                st.markdown("### ğŸ“Š L2 SW ì¥ì•  ë¶„ì„ ì°¨íŠ¸")
                chart_tab1, chart_tab2 = st.tabs([
                    "ğŸ“ˆ ì¥ì•  ë°œìƒ ì¶”ì´", "ğŸ¯ ì›ì¸ë³„ ë¶„ì„"
                ])
                with chart_tab1:
                    st.markdown("#### ğŸ“ˆ L2 SW ì¥ì•  ë°œìƒ ì¶”ì´ ë¶„ì„")
                    trend_chart = create_incident_trend_chart(df, business_name)
                    if trend_chart:
                        st.plotly_chart(trend_chart, use_container_width=True)
                    else:
                        st.info("ì¥ì•  ë°œìƒ ì¶”ì´ ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                with chart_tab2:
                    st.markdown("#### ğŸ¯ L2 SW ì¥ì•  ì›ì¸ ë¶„ì„")
                    cause_chart = create_cause_analysis_chart(df, business_name)
                    if cause_chart:
                        st.plotly_chart(cause_chart, use_container_width=True)
                    else:
                        st.info("ì¥ì•  ì›ì¸ ë¶„ì„ ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                if business_name is None:
                    st.markdown("### ğŸ¢ êµ­ì‚¬ë³„ L2 SW ì¥ì•  ë°œìƒ í˜„í™©")
                    office_chart = create_office_heatmap(df)
                    if office_chart:
                        st.plotly_chart(office_chart, use_container_width=True)
                    else:
                        st.info("êµ­ì‚¬ë³„ ë¶„ì„ ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.markdown("### ğŸ‘¨â€ğŸ’¼ ìš´ìš©íŒ€ë³„ L2 SW ì¥ì•  ë°œìƒ í˜„í™©")
                    team_chart = create_team_heatmap(df)
                    if team_chart:
                        st.plotly_chart(team_chart, use_container_width=True)
                    else:
                        st.info("ìš´ìš©íŒ€ë³„ ë¶„ì„ ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.markdown("### ğŸ“‹ L2 SW ìƒì„¸ ë¶„ì„ ê²°ê³¼")
                if analysis:
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write("**ğŸ“ˆ L2 SW ì¥ì•  íŒ¨í„´ ë¶„ì„:**")
                        if 'category' in analysis['patterns']:
                            st.write("**ğŸ” ì¥ì• ë¶„ë¥˜ë³„:**")
                            for category, count in analysis['patterns']['category'].items():
                                st.write(f"- {category}: {count}íšŒ")
                        if 'cause' in analysis['patterns']:
                            st.write("**ğŸ¯ ì›ì¸ë³„:**")
                            for cause, count in list(analysis['patterns']['cause'].items())[:10]:
                                st.write(f"- {cause}: {count}íšŒ")
                    with col2:
                        st.write("**ğŸ“… L2 SW ì‹œê°„ë³„ íŒ¨í„´:**")
                        if 'monthly' in analysis['patterns']:
                            st.write("**ğŸ“… ì›”ë³„ ë°œìƒ:**")
                            # ì›”ë³„ ë°ì´í„°ë¥¼ ê°€ë¡œë¡œ í‘œì‹œí•˜ê¸° ìœ„í•´ 3ê°œì”© ê·¸ë£¹í™”
                            monthly_data = list(analysis['patterns']['monthly'].items())
                            for i in range(0, len(monthly_data), 3):
                                month_group = monthly_data[i:i+3]
                                month_text = " | ".join([f"{month}ì›”:{count}íšŒ" for month, count in month_group])
                                st.write(f"- {month_text}")
                        if 'seasonal' in analysis['patterns']:
                            st.write("**ğŸŒ¤ï¸ ê³„ì ˆë³„ ë°œìƒ:**")
                            seasonal_text = " | ".join([f"{season}:{count}íšŒ" for season, count in analysis['patterns']['seasonal'].items()])
                            st.write(f"- {seasonal_text}")
                        
                        # ìš°ê¸°ì²  ë¶„ì„ ì¶”ê°€
                        if 'rainy_season' in analysis['patterns']:
                            st.write("**ğŸŒ§ï¸ ìš°ê¸°ì² (6ì›”~9ì›”) ë¶„ì„:**")
                            rainy_data = analysis['patterns']['rainy_season']
                            st.write(f"- ì´ ì¥ì• : {rainy_data['total_incidents']}íšŒ ({rainy_data['percentage']}%)")
                            
                            if 'rainy_causes' in analysis['patterns']:
                                st.write("**ğŸ¯ ìš°ê¸°ì²  ì£¼ìš” ì¥ì•  ì›ì¸ Top3:**")
                                rainy_causes = analysis['patterns']['rainy_causes']
                                for i, (cause, count) in enumerate(rainy_causes.items(), 1):
                                    st.write(f"  {i}. {cause}: {count}íšŒ")
                    st.markdown("### âš ï¸ L2 SW ì¥ì•  ìœ„í—˜ë„ ì˜ˆì¸¡")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write("**ğŸ” ìœ„í—˜ë„ ë¶„ì„:**")
                        for reason in risk_prediction['reasons']:
                            st.write(f"â€¢ {reason}")
                    with col2:
                        st.write("**ğŸ’¡ L2 SW ì˜ˆë°© ê¶Œì¥ì‚¬í•­:**")
                        for recommendation in risk_prediction['recommendations']:
                            st.write(f"â€¢ {recommendation}")
                        
                        # ìš°ê¸°ì²  ì˜ˆë°©ì ê²€ í™œë™ ì¶”ê°€
                        if 'rainy_causes' in analysis['patterns']:
                            st.write("**ğŸŒ§ï¸ ìš°ê¸°ì²  ì˜ˆë°©ì ê²€ í™œë™:**")
                            rainy_recommendations = generate_rainy_season_recommendations(analysis['patterns']['rainy_causes'])
                            for recommendation in rainy_recommendations:
                                st.write(f"â€¢ {recommendation}")
                st.markdown("### ğŸ“‹ L2 SW ìƒì„¸ ì¥ì•  ì´ë ¥")
                filtered_df = df.copy()
                if 'ì¥ì• ë°œìƒì‹œê°' in filtered_df.columns:
                    filtered_df = filtered_df.sort_values('ì¥ì• ë°œìƒì‹œê°', ascending=False)
                st.dataframe(filtered_df, use_container_width=True)
                csv = filtered_df.to_csv(index=False, encoding='cp949')
                filename = f"L2SW_{business_name or 'ì „ì²´'}_ì¥ì• ì´ë ¥ë¶„ì„.csv"
                st.download_button(
                    f"ğŸ“¥ L2 SW ì¥ì•  ì´ë ¥ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", 
                    csv, 
                    file_name=filename, 
                    mime="text/csv"
                )
        with subtab2:
            subtab_team, subtab_office, subtab_voc, subtab_action = st.tabs(["íŒ€ë³„ ì¤‘ë³µì¥ì•  ë¶„ì„", "ì§€ì—­(êµ­ì‚¬ë³„) ì¥ì• ë¶„ì„", "í˜„ì¥ TMí™œë™", "ì•¡ì…˜ì•„ì´í…œ"])
            with subtab_team:
                df = st.session_state.incident_history.copy()
                team_group = df.groupby(['ìš´ìš©íŒ€', 'ì‚¬ì—…ì¥ëª…']).size().reset_index(name='ì¥ì• ê±´ìˆ˜')
                duplicated = team_group[team_group['ì¥ì• ê±´ìˆ˜'] >= 2]
                team_list = sorted(duplicated['ìš´ìš©íŒ€'].unique())
                team_options = ['ìš´ìš©íŒ€ì„ ì„ íƒí•˜ì„¸ìš”'] + team_list
                selected_team = st.selectbox("ìš´ìš©íŒ€ì„ ì„ íƒí•˜ì„¸ìš”", options=team_options, index=0, key="team_select_team")
                detail_cols = ['ì¥ì• ë¶„ë¥˜', 'ì›ì¸', 'ì¡°ì¹˜1', 'ì¡°ì¹˜2', 'ì¶œë™êµ¬ë¶„', 'ì¥ì• ë°œìƒì‹œê°']
                available_cols = [col for col in detail_cols if col in df.columns]
                def parse_datetime_multi(x):
                    for fmt in ("%Y/%m/%d %H:%M", "%Y-%m-%d %H:%M"):
                        try:
                            return pd.to_datetime(x, format=fmt, errors="raise")
                        except:
                            continue
                    try:
                        return pd.to_datetime(x, errors="coerce")
                    except:
                        return pd.NaT
                def is_night(x):
                    t = parse_datetime_multi(x)
                    if pd.isnull(t):
                        return ''
                    # ì•¼ê°„ì¥ì• : ë‹¹ì¼ 18ì‹œ ì´í›„ë¶€í„° ë‹¤ìŒë‚  07ì‹œ59ë¶„ê¹Œì§€
                    hour = t.hour
                    return 'ì•¼ê°„ ì¥ì• ' if (hour >= 18 or hour < 8) else ''
                if selected_team != 'ìš´ìš©íŒ€ì„ ì„ íƒí•˜ì„¸ìš”':
                    team_df = duplicated[duplicated['ìš´ìš©íŒ€'] == selected_team].copy()
                    if not team_df.empty:
                        # ìš”ì•½ í‘œ ìƒì„±
                        summary_list = []
                        for _, row in team_df.iterrows():
                            biz = row['ì‚¬ì—…ì¥ëª…']
                            detail = df[(df['ìš´ìš©íŒ€'] == selected_team) & (df['ì‚¬ì—…ì¥ëª…'] == biz)].copy()
                            if 'ì¶œë™êµ¬ë¶„' in detail.columns:
                                detail = detail[detail['ì¶œë™êµ¬ë¶„'] == 'ì¶œë™'].copy()
                            # ì•¼ê°„ ì¥ì•  ê±´ìˆ˜ (18ì‹œ~07ì‹œ59ë¶„)
                            night_count = 0
                            if 'ì¥ì• ë°œìƒì‹œê°' in detail.columns:
                                night_count = detail['ì¥ì• ë°œìƒì‹œê°'].apply(lambda x: 
                                    parse_datetime_multi(x).hour >= 18 or parse_datetime_multi(x).hour < 8 
                                    if not pd.isnull(parse_datetime_multi(x)) else False
                                ).sum()
                            # ìµœê·¼ ì¥ì• ì¼
                            recent = ''
                            if 'ì¥ì• ë°œìƒì‹œê°' in detail.columns and not detail.empty:
                                recent_dt = detail['ì¥ì• ë°œìƒì‹œê°'].apply(parse_datetime_multi)
                                if not recent_dt.isnull().all():
                                    recent = recent_dt.max().strftime('%Y-%m-%d %H:%M')
                            # ì£¼ìš” ì¥ì•  ì›ì¸(ìƒìœ„ 2ê°œ) - ë¹„ìœ¨ë¡œ í‘œì‹œ
                            main_causes = ''
                            if 'ì›ì¸' in detail.columns and not detail['ì›ì¸'].isnull().all():
                                cause_counts = detail['ì›ì¸'].value_counts()
                                total_causes = len(detail)
                                top_causes = cause_counts.head(2)
                                cause_percentages = []
                                for cause, count in top_causes.items():
                                    percentage = round((count / total_causes) * 100, 1)
                                    cause_percentages.append(f"{cause}({percentage}%)")
                                main_causes = ', '.join(cause_percentages)
                            
                            # ì‹¤ì œ ì¶œë™ íšŸìˆ˜ ê³„ì‚°
                            dispatch_count = 0
                            if 'ì¶œë™êµ¬ë¶„' in detail.columns:
                                dispatch_count = len(detail[detail['ì¶œë™êµ¬ë¶„'] == 'ì¶œë™'])
                            
                            # ì¤‘ë³µë°œìƒ ê°€ëŠ¥ì„± ì˜ˆì¸¡
                            duplicate_risk = ''
                            if row['ì¥ì• ê±´ìˆ˜'] >= 5:
                                duplicate_risk = 'ğŸ”´ ë†’ìŒ (5íšŒ ì´ìƒ)'
                            elif row['ì¥ì• ê±´ìˆ˜'] >= 3:
                                duplicate_risk = 'ğŸŸ  ë³´í†µ (3-4íšŒ)'
                            else:
                                duplicate_risk = 'ğŸŸ¢ ë‚®ìŒ (2íšŒ)'
                            
                            summary_list.append({
                                'ì‚¬ì—…ì¥ëª…': biz,
                                'ì¥ì• ê±´ìˆ˜': row['ì¥ì• ê±´ìˆ˜'],
                                'ì¶œë™íšŸìˆ˜': dispatch_count,
                                'ì•¼ê°„ì¥ì• ê±´ìˆ˜': night_count,
                                'ìµœê·¼ì¥ì• ì¼': recent,
                                'ì£¼ìš”ì¥ì• ì›ì¸': main_causes,
                                'ì¤‘ë³µë°œìƒê°€ëŠ¥ì„±': duplicate_risk
                            })
                        summary_df = pd.DataFrame(summary_list)
                        if not summary_df.empty:
                            # ìš´ìš©ìê°€ ìƒìœ„ ê°œìˆ˜ ì§ì ‘ ì…ë ¥
                            top_n = st.number_input("ìƒìœ„ ëª‡ ê°œ ì‚¬ì—…ì¥ì„ ë³¼ê¹Œìš”?", min_value=1, max_value=100, value=5, step=1, key="top_n_summary")
                            summary_df = summary_df.sort_values('ì¥ì• ê±´ìˆ˜', ascending=False).head(top_n)
                            st.markdown(f'#### ğŸš¨ ì¥ì•  ì§‘ì¤‘ ê´€ë¦¬ í•„ìš” ì‚¬ì—…ì¥(ìƒìœ„ {top_n}ê°œ) - ì¤‘ë³µë°œìƒ ê°€ëŠ¥ì„± í¬í•¨')
                            st.dataframe(summary_df, use_container_width=True)
                            
                            # ìƒì„¸ ì´ë ¥ ê²€ìƒ‰ ì„¹ì…˜ ë¶„ë¦¬
                            st.markdown('#### ğŸ“‹ ì‚¬ì—…ì¥ë³„ ìƒì„¸ ì´ë ¥ ì¡°íšŒ')
                            search_keyword = st.text_input("ìƒì„¸ ì´ë ¥ì„ ë³´ê³  ì‹¶ì€ ì‚¬ì—…ì¥ëª…ì„ ê²€ìƒ‰í•˜ì„¸ìš”", value="", key="team_detail_search")
                            
                            if search_keyword:
                                # ê²€ìƒ‰ëœ ì‚¬ì—…ì¥ì˜ ìƒì„¸ ì´ë ¥ë§Œ í‘œì‹œ
                                filtered_df = summary_df[summary_df['ì‚¬ì—…ì¥ëª…'].str.contains(search_keyword, case=False, na=False)]
                                if not filtered_df.empty:
                                    selected_biz = filtered_df.iloc[0]['ì‚¬ì—…ì¥ëª…']
                                    detail = df[(df['ìš´ìš©íŒ€'] == selected_team) & (df['ì‚¬ì—…ì¥ëª…'] == selected_biz)].copy()
                                    if 'ì¶œë™êµ¬ë¶„' in detail.columns:
                                        detail = detail[detail['ì¶œë™êµ¬ë¶„'] == 'ì¶œë™'].copy()
                                    if 'ì¥ì• ë°œìƒì‹œê°' in detail.columns:
                                        detail['ì•¼ê°„êµ¬ë¶„'] = detail['ì¥ì• ë°œìƒì‹œê°'].apply(is_night)
                                    show_cols = [col for col in ['ì¥ì• ë¶„ë¥˜', 'ì›ì¸', 'ì¡°ì¹˜1', 'ì¡°ì¹˜2', 'ì¶œë™êµ¬ë¶„', 'ì¥ì• ë°œìƒì‹œê°', 'ì•¼ê°„êµ¬ë¶„'] if col in detail.columns]
                                    st.markdown(f"#### ğŸ“‹ {selected_biz} ìƒì„¸ ì´ë ¥")
                                    st.dataframe(detail[show_cols], use_container_width=True)
                                else:
                                    st.info("ê²€ìƒ‰ ê²°ê³¼ì— í•´ë‹¹í•˜ëŠ” ì‚¬ì—…ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.info("ì‚¬ì—…ì¥ëª…ì„ ê²€ìƒ‰í•˜ë©´ ìƒì„¸ ì´ë ¥ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        else:
                            st.info("ì„ íƒí•œ ìš´ìš©íŒ€ì— ì¤‘ë³µ ì¥ì•  ë°œìƒ ì‚¬ì—…ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.info("ì„ íƒí•œ ìš´ìš©íŒ€ì— ì¤‘ë³µ ì¥ì•  ë°œìƒ ì‚¬ì—…ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.info("ìš´ìš©íŒ€ì„ ì„ íƒí•˜ë©´ ë¶„ì„ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
            with subtab_office:
                df = st.session_state.incident_history.copy()
                # ìš´ìš©íŒ€ ëª©ë¡
                team_list = sorted(df['ìš´ìš©íŒ€'].dropna().unique())
                selected_team = st.selectbox("ìš´ìš©íŒ€ì„ ì„ íƒí•˜ì„¸ìš”", options=['ìš´ìš©íŒ€ì„ ì„ íƒí•˜ì„¸ìš”'] + team_list, index=0, key="team_select_office")
                if selected_team != 'ìš´ìš©íŒ€ì„ ì„ íƒí•˜ì„¸ìš”':
                    team_df = df[df['ìš´ìš©íŒ€'] == selected_team].copy()
                    # ì§€ì—­(êµ­ì‚¬)ë³„ ì¥ì•  ê±´ìˆ˜ ì§‘ê³„
                    if 'ì§€ì—­' in team_df.columns:
                        region_group = team_df.groupby('ì§€ì—­').size().reset_index(name='ì¥ì• ê±´ìˆ˜').sort_values('ì¥ì• ê±´ìˆ˜', ascending=False)
                        st.dataframe(region_group, use_container_width=True)
                        # ìƒìœ„ 3ê°œ êµ­ì‚¬ ì¶”ì¶œ
                        top_regions = region_group.head(3)['ì§€ì—­'].tolist()
                        # ê° êµ­ì‚¬ë³„ ì¥ì•  ì›ì¸ Top3 í‘œì‹œ
                        for region in top_regions:
                            region_df = team_df[team_df['ì§€ì—­'] == region].copy()
                            if 'ì›ì¸' in region_df.columns:
                                cause_counts = region_df['ì›ì¸'].value_counts().head(3)
                                cause_str = ', '.join([f"{cause}({count}ê±´)" for cause, count in cause_counts.items()])
                                st.markdown(f"**ğŸ¢ {region} ì£¼ìš” ì¥ì•  ì›ì¸:** {cause_str}")
                        # ê·¸ë˜í”„
                        import plotly.express as px
                        fig = px.bar(region_group, x='ì§€ì—­', y='ì¥ì• ê±´ìˆ˜', title=f"{selected_team} - ì§€ì—­(êµ­ì‚¬)ë³„ ì¥ì•  ê±´ìˆ˜")
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("ë°ì´í„°ì— 'ì§€ì—­' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.info("ìš´ìš©íŒ€ì„ ì„ íƒí•˜ë©´ ì§€ì—­(êµ­ì‚¬)ë³„ ì¥ì• ë¶„ì„ì´ í‘œì‹œë©ë‹ˆë‹¤.")
            with subtab_voc:
                st.markdown("## ğŸ“ í˜„ì¥ TMí™œë™ ëŒ€ìƒ ì‚¬ì—…ì¥ ê´€ë¦¬")
                st.markdown("""
                <div style="background-color: #f0f2f6; padding: 15px; border-radius: 8px; margin-bottom: 15px;">
                    <h4>ğŸ“ í˜„ì¥ TMí™œë™ì´ë€?</h4>
                    <p>í…”ë ˆë§ˆì¼€íŒ… í™œë™ì„ í†µí•œ VOC ë°©ì–´ í™œë™ì…ë‹ˆë‹¤:</p>
                    <ul>
                        <li>ğŸ” <strong>ì—°ë½ì²˜ ì—…ë°ì´íŠ¸</strong>: ì‹¤ì‹œê°„ ì¥ì•  ëŒ€ì‘ ì‹œ ì‚¬ì—…ì¥ ì—°ë½ì²˜ ì •ë³´ ê°±ì‹ </li>
                        <li>ğŸ“± <strong>í˜„ì¥ ì—°ë½ì²˜ íšë“</strong>: í˜„ì¥ ì§ì›ë“¤ì´ ì§ì ‘ ì—°ë½ì²˜ ì •ë³´ ìˆ˜ì§‘</li>
                        <li>ğŸ›¡ï¸ <strong>VOC ë°©ì–´</strong>: ì‚¬ì „ ì—°ë½ì„ í†µí•œ ê³ ê° ë¶ˆë§Œ ì‚¬ì „ ì°¨ë‹¨</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)
                df = st.session_state.incident_history.copy()
                team_list = sorted(df['ìš´ìš©íŒ€'].dropna().unique())
                selected_team = st.selectbox("ìš´ìš©íŒ€ì„ ì„ íƒí•˜ì„¸ìš”", options=['ìš´ìš©íŒ€ì„ ì„ íƒí•˜ì„¸ìš”'] + team_list, index=0, key='team_select_voc')
                
                # TMí™œë™ ëŒ€ìƒ ì„ ì • ê¸°ì¤€
                st.markdown("### ğŸ¯ TMí™œë™ ëŒ€ìƒ ì„ ì • ê¸°ì¤€")
                col1, col2 = st.columns(2)
                with col1:
                    min_incidents = st.number_input("ìµœì†Œ ì¥ì•  ë°œìƒ íšŸìˆ˜", min_value=1, value=2, help="ì´ íšŸìˆ˜ ì´ìƒ ì¥ì• ê°€ ë°œìƒí•œ ì‚¬ì—…ì¥ì„ ëŒ€ìƒìœ¼ë¡œ ì„ ì •")
                with col2:
                    include_night = st.checkbox("ì•¼ê°„ ì¥ì•  ë°œìƒ ì‚¬ì—…ì¥ ìš°ì„ ", value=True, help="ì•¼ê°„ ì¥ì• ê°€ ë°œìƒí•œ ì‚¬ì—…ì¥ì„ ìš°ì„  ëŒ€ìƒìœ¼ë¡œ ì„ ì •")
                def parse_datetime_multi(x):
                    for fmt in ("%Y/%m/%d %H:%M", "%Y-%m-%d %H:%M"):
                        try:
                            return pd.to_datetime(x, format=fmt, errors="raise")
                        except:
                            continue
                    try:
                        return pd.to_datetime(x, errors="coerce")
                    except:
                        return pd.NaT
                if selected_team != 'ìš´ìš©íŒ€ì„ ì„ íƒí•˜ì„¸ìš”':
                    team_df = df[df['ìš´ìš©íŒ€'] == selected_team].copy()
                    
                    # TMí™œë™ ëŒ€ìƒ ì‚¬ì—…ì¥ ì„ ì •
                    if 'ì¥ì• ë°œìƒì‹œê°' in team_df.columns and 'ì¶œë™êµ¬ë¶„' in team_df.columns:
                        team_df['dt'] = team_df['ì¥ì• ë°œìƒì‹œê°'].apply(parse_datetime_multi)
                        
                        # ì „ì²´ ì¥ì•  ë°œìƒ ì‚¬ì—…ì¥ ë¶„ì„
                        incident_by_biz = team_df.groupby(['ì‚¬ì—…ì¥ëª…', 'ì§€ì—­']).size().reset_index(name='ì´ì¥ì• íšŸìˆ˜')
                        
                        # ì•¼ê°„ ì¥ì•  ë°œìƒ ì‚¬ì—…ì¥ ë¶„ì„
                        night_df = team_df[(team_df['ì¶œë™êµ¬ë¶„'] == 'ì¶œë™') & (team_df['dt'].dt.hour >= 18) | ((team_df['ì¶œë™êµ¬ë¶„'] == 'ì¶œë™') & (team_df['dt'].dt.hour < 8))].copy()
                        night_count_by_biz = night_df.groupby(['ì‚¬ì—…ì¥ëª…', 'ì§€ì—­']).size().reset_index(name='ì•¼ê°„ì¥ì• íšŸìˆ˜')
                        
                        # TMí™œë™ ëŒ€ìƒ ì„ ì • (ê¸°ì¤€ì— ë”°ë¼)
                        tm_targets = incident_by_biz[incident_by_biz['ì´ì¥ì• íšŸìˆ˜'] >= min_incidents].copy()
                        
                        if include_night:
                            # ì•¼ê°„ ì¥ì•  ì‚¬ì—…ì¥ê³¼ ë³‘í•©
                            tm_targets = tm_targets.merge(night_count_by_biz, on=['ì‚¬ì—…ì¥ëª…', 'ì§€ì—­'], how='left')
                            tm_targets['ì•¼ê°„ì¥ì• íšŸìˆ˜'] = tm_targets['ì•¼ê°„ì¥ì• íšŸìˆ˜'].fillna(0)
                            # ì•¼ê°„ ì¥ì• ê°€ ìˆëŠ” ì‚¬ì—…ì¥ì„ ìš°ì„  ì •ë ¬
                            tm_targets = tm_targets.sort_values(['ì•¼ê°„ì¥ì• íšŸìˆ˜', 'ì´ì¥ì• íšŸìˆ˜'], ascending=[False, False])
                        else:
                            tm_targets = tm_targets.sort_values('ì´ì¥ì• íšŸìˆ˜', ascending=False)
                        
                        # ìš´ìš©ì ë©”ëª¨(ì—°ë½ì²˜) ì»¬ëŸ¼ ì¶”ê°€
                        if 'ìš´ìš©ìë©”ëª¨' in team_df.columns:
                            memos = team_df.groupby('ì‚¬ì—…ì¥ëª…')['ìš´ìš©ìë©”ëª¨'].first().reset_index()
                            tm_targets = tm_targets.merge(memos, on='ì‚¬ì—…ì¥ëª…', how='left')
                        
                        # TMí™œë™ ìš°ì„ ìˆœìœ„ ê³„ì‚°
                        tm_targets['TMìš°ì„ ìˆœìœ„'] = tm_targets.apply(lambda row: 
                            'ğŸ”´ ê¸´ê¸‰' if row['ì•¼ê°„ì¥ì• íšŸìˆ˜'] > 0 and row['ì´ì¥ì• íšŸìˆ˜'] >= 5 else
                            'ğŸŸ  ë†’ìŒ' if row['ì•¼ê°„ì¥ì• íšŸìˆ˜'] > 0 or row['ì´ì¥ì• íšŸìˆ˜'] >= 3 else
                            'ğŸŸ¡ ë³´í†µ', axis=1)
                        
                        # ê¸´ê¸‰ ëŒ€ìƒë§Œ í•„í„°ë§
                        urgent_targets = tm_targets[tm_targets['TMìš°ì„ ìˆœìœ„'] == 'ğŸ”´ ê¸´ê¸‰'].copy()
                        
                        # í‘œì‹œí•  ì»¬ëŸ¼ ì„ íƒ
                        show_cols = [col for col in ['ì‚¬ì—…ì¥ëª…', 'ì§€ì—­', 'ì´ì¥ì• íšŸìˆ˜', 'ì•¼ê°„ì¥ì• íšŸìˆ˜', 'TMìš°ì„ ìˆœìœ„', 'ìš´ìš©ìë©”ëª¨'] if col in urgent_targets.columns]
                        
                        st.markdown(f"### ğŸ“ TMí™œë™ ê¸´ê¸‰ ëŒ€ìƒ ì‚¬ì—…ì¥ (ì´ {len(urgent_targets)}ê°œ)")
                        if not urgent_targets.empty:
                            st.dataframe(urgent_targets[show_cols], use_container_width=True)
                            
                            # ê¸´ê¸‰ ëŒ€ìƒ ì‚¬ì—…ì¥ì—ì„œ ë°”ë¡œ ì—°ë½ì²˜ ê²€ìƒ‰
                            st.markdown("##### ğŸš¨ ê¸´ê¸‰ ëŒ€ìƒ ì‚¬ì—…ì¥ ì—°ë½ì²˜ ê²€ìƒ‰")
                            selected_urgent = st.selectbox(
                                "ì—°ë½ì²˜ë¥¼ ê²€ìƒ‰í•  ê¸´ê¸‰ ëŒ€ìƒ ì‚¬ì—…ì¥ì„ ì„ íƒí•˜ì„¸ìš”",
                                options=urgent_targets['ì‚¬ì—…ì¥ëª…'].tolist(),
                                key="urgent_business_select"
                            )
                            
                            if selected_urgent:
                                selected_row = urgent_targets[urgent_targets['ì‚¬ì—…ì¥ëª…'] == selected_urgent].iloc[0]
                                st.info(f"ì„ íƒëœ ì‚¬ì—…ì¥: {selected_urgent} (ì´ {selected_row['ì´ì¥ì• íšŸìˆ˜']}íšŒ ì¥ì• , ì•¼ê°„ {selected_row['ì•¼ê°„ì¥ì• íšŸìˆ˜']}íšŒ)")
                                
                                col1, col2 = st.columns([2, 1])
                                with col1:
                                    quick_search_business = st.text_input("ì‚¬ì—…ì¥ëª… (ìˆ˜ì • ê°€ëŠ¥)", value=selected_urgent, key="quick_business")
                                with col2:
                                    quick_search_address = st.text_input("ì£¼ì†Œ (ì„ íƒì‚¬í•­)", placeholder="ì§€ì—­ ì •ë³´ ì…ë ¥", key="quick_address")
                                
                                if st.button("ğŸ” ê¸´ê¸‰ ëŒ€ìƒ ì—°ë½ì²˜ ì¦‰ì‹œ ê²€ìƒ‰", type="primary", key="urgent_contact_search"):
                                    with st.spinner(f"{selected_urgent} ì—°ë½ì²˜ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                                        # ì¹´ì¹´ì˜¤ API ê²€ìƒ‰
                                        kakao_result = search_contact_enhanced(quick_search_business, quick_search_address)
                                        
                                        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
                                        st.markdown("##### ğŸ“ ê¸´ê¸‰ ëŒ€ìƒ ì—°ë½ì²˜ ê²€ìƒ‰ ê²°ê³¼")
                                        col1, col2, col3 = st.columns(3)
                                        
                                        with col1:
                                            st.markdown("**ğŸ” ì¹´ì¹´ì˜¤ API ê²°ê³¼**")
                                            if kakao_result:
                                                st.success(f"âœ… ì—°ë½ì²˜: {kakao_result}")
                                                if st.button("ğŸ’¾ ê¸´ê¸‰ ëŒ€ìƒ ì—°ë½ì²˜ ì €ì¥", key="save_urgent_contact"):
                                                    st.success(f"{selected_urgent} ì—°ë½ì²˜ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                            else:
                                                st.warning("âŒ ì¹´ì¹´ì˜¤ APIì—ì„œ ì—°ë½ì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                        
                                        with col2:
                                            st.markdown("**ğŸŒ êµ¬ê¸€ ê²€ìƒ‰**")
                                            google_links = get_contact_search_links(quick_search_business, quick_search_address)
                                            if google_links:
                                                for i, (label, url) in enumerate(google_links[:2]):
                                                    st.link_button(f"{label} {i+1}", url)
                                            else:
                                                st.info("êµ¬ê¸€ ê²€ìƒ‰ ë§í¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                        
                                        with col3:
                                            st.markdown("**ğŸ” ë„¤ì´ë²„ ê²€ìƒ‰**")
                                            naver_result = simulate_naver_search(quick_search_business, quick_search_address)
                                            if naver_result:
                                                st.link_button("ë„¤ì´ë²„ ê²€ìƒ‰", naver_result)
                                            else:
                                                st.info("ë„¤ì´ë²„ ê²€ìƒ‰ ë§í¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            st.info("ğŸ”´ ê¸´ê¸‰ ëŒ€ìƒ ì‚¬ì—…ì¥ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ì‚¬ì—…ì¥ì´ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜ë˜ê³  ìˆìŠµë‹ˆë‹¤!")
                        
                        # í†µê³„ ì •ë³´ (ê¸´ê¸‰ ëŒ€ìƒ ì¤‘ì‹¬)
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ì´ ëŒ€ìƒ ì‚¬ì—…ì¥", f"{len(tm_targets)}ê°œ")
                        with col2:
                            st.metric("ğŸ”´ ê¸´ê¸‰ ëŒ€ìƒ", f"{len(urgent_targets)}ê°œ")
                        with col3:
                            urgent_night_count = len(urgent_targets[urgent_targets['ì•¼ê°„ì¥ì• íšŸìˆ˜'] > 0])
                            st.metric("ê¸´ê¸‰ ì•¼ê°„ ì¥ì• ", f"{urgent_night_count}ê°œ")
                        
       
                        
                        # TMí™œë™ ì´ë ¥ ë° ì—°ë½ì²˜ ì—…ë°ì´íŠ¸
                        st.markdown('#### ğŸ“ TMí™œë™ ì´ë ¥ ë° ì—°ë½ì²˜ ê´€ë¦¬')
                        
                        # ì—°ë½ì²˜ ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€
                        st.markdown("##### ğŸ” ì—°ë½ì²˜ ê²€ìƒ‰ ë° ì—…ë°ì´íŠ¸")
                        col1, col2 = st.columns([2, 1])
                        with col1:
                            search_business = st.text_input("ì‚¬ì—…ì¥ëª… ê²€ìƒ‰", placeholder="ì˜ˆ: í•´ìš´ëŒ€ ì•„íŒŒíŠ¸, ë¡¯ë°ë°±í™”ì ...", key="tm_contact_search")
                        with col2:
                            search_address = st.text_input("ì£¼ì†Œ ê²€ìƒ‰", placeholder="ì˜ˆ: ë¶€ì‚° í•´ìš´ëŒ€êµ¬...", key="tm_address_search")
                        
                        if st.button("ğŸ” ì—°ë½ì²˜ ê²€ìƒ‰ ì‹¤í–‰", type="primary", key="tm_contact_search_btn"):
                            if search_business or search_address:
                                with st.spinner("ì—°ë½ì²˜ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                                    # ì¹´ì¹´ì˜¤ API ê²€ìƒ‰
                                    kakao_result = search_contact_enhanced(search_business, search_address)
                                    
                                    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
                                    st.markdown("##### ğŸ“ ê²€ìƒ‰ ê²°ê³¼")
                                    col1, col2, col3 = st.columns(3)
                                    
                                    with col1:
                                        st.markdown("**ğŸ” ì¹´ì¹´ì˜¤ API ê²€ìƒ‰ ê²°ê³¼**")
                                        if kakao_result:
                                            st.success(f"âœ… ì—°ë½ì²˜ ë°œê²¬: {kakao_result}")
                                            # ì—°ë½ì²˜ ì €ì¥ ë²„íŠ¼
                                            if st.button("ğŸ’¾ ì—°ë½ì²˜ ì €ì¥", key="save_kakao_contact"):
                                                st.success("ì—°ë½ì²˜ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                        else:
                                            st.warning("âŒ ì¹´ì¹´ì˜¤ APIì—ì„œ ì—°ë½ì²˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                    
                                    with col2:
                                        st.markdown("**ğŸŒ êµ¬ê¸€ ê²€ìƒ‰ ë§í¬**")
                                        google_links = get_contact_search_links(search_business, search_address)
                                        if google_links:
                                            for i, (label, url) in enumerate(google_links[:2]):
                                                st.link_button(f"{label} {i+1}", url)
                                        else:
                                            st.info("êµ¬ê¸€ ê²€ìƒ‰ ë§í¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                    
                                    with col3:
                                        st.markdown("**ğŸ” ë„¤ì´ë²„ ê²€ìƒ‰ ë§í¬**")
                                        naver_result = simulate_naver_search(search_business, search_address)
                                        if naver_result:
                                            st.link_button("ë„¤ì´ë²„ ê²€ìƒ‰", naver_result)
                                        else:
                                            st.info("ë„¤ì´ë²„ ê²€ìƒ‰ ë§í¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                st.warning("ì‚¬ì—…ì¥ëª… ë˜ëŠ” ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                        
                        # ì‚¬ì—…ì¥ë³„ ìƒì„¸ ì •ë³´ ì¡°íšŒ
                        if st.button("ğŸ“‹ ì‚¬ì—…ì¥ë³„ ìƒì„¸ ì •ë³´ ì¡°íšŒ", type="primary", key="biz_tm_detail"):
                            # í•´ë‹¹ íŒ€ì˜ ëª¨ë“  ì‚¬ì—…ì¥ ì¥ì•  íšŸìˆ˜ ì§‘ê³„
                            all_incidents_by_biz = team_df.groupby(['ì‚¬ì—…ì¥ëª…', 'ì§€ì—­']).size().reset_index(name='ì´ì¥ì• íšŸìˆ˜')
                            # ì•¼ê°„ ì¥ì•  íšŸìˆ˜ ì¶”ê°€
                            night_incidents_by_biz = team_df[(team_df['dt'].dt.hour >= 18) | (team_df['dt'].dt.hour < 8)].groupby(['ì‚¬ì—…ì¥ëª…']).size().reset_index(name='ì•¼ê°„ì¥ì• íšŸìˆ˜')
                            all_incidents_by_biz = all_incidents_by_biz.merge(night_incidents_by_biz, on='ì‚¬ì—…ì¥ëª…', how='left').fillna(0)
                            # ìµœê·¼ ì¥ì• ì¼ ì¶”ê°€
                            recent_incidents = team_df.groupby('ì‚¬ì—…ì¥ëª…')['ì¥ì• ë°œìƒì‹œê°'].max().reset_index()
                            recent_incidents['ìµœê·¼ì¥ì• ì¼'] = recent_incidents['ì¥ì• ë°œìƒì‹œê°'].apply(lambda x: parse_datetime_multi(x).strftime('%Y-%m-%d %H:%M') if not pd.isnull(parse_datetime_multi(x)) else '')
                            all_incidents_by_biz = all_incidents_by_biz.merge(recent_incidents[['ì‚¬ì—…ì¥ëª…', 'ìµœê·¼ì¥ì• ì¼']], on='ì‚¬ì—…ì¥ëª…', how='left')
                            # ì£¼ìš” ì¥ì•  ì›ì¸ ì¶”ê°€
                            cause_by_biz = team_df.groupby('ì‚¬ì—…ì¥ëª…')['ì›ì¸'].apply(lambda x: ', '.join(x.value_counts().head(2).index)).reset_index(name='ì£¼ìš”ì¥ì• ì›ì¸')
                            all_incidents_by_biz = all_incidents_by_biz.merge(cause_by_biz, on='ì‚¬ì—…ì¥ëª…', how='left')
                            # ì¥ì•  íšŸìˆ˜ ë§ì€ ìˆœìœ¼ë¡œ ì •ë ¬
                            all_incidents_by_biz = all_incidents_by_biz.sort_values('ì´ì¥ì• íšŸìˆ˜', ascending=False)
                            st.markdown(f"#### ğŸš¨ {selected_team} ì‚¬ì—…ì¥ë³„ ì¥ì• ì´ë ¥ (ì¥ì•  íšŸìˆ˜ ë§ì€ ìˆœ)")
                            st.dataframe(all_incidents_by_biz, use_container_width=True)
                        else:
                            st.info("ë°ì´í„°ì— 'ì¥ì• ë°œìƒì‹œê°' ë˜ëŠ” 'ì¶œë™êµ¬ë¶„' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.info("ìš´ìš©íŒ€ì„ ì„ íƒí•˜ë©´ ì•¼ê°„ ì¶œë™ ì‚¬ì—…ì¥ì´ í‘œì‹œë©ë‹ˆë‹¤.")
            
            with subtab_action:
                st.markdown("## ğŸ¯ ì•¡ì…˜ì•„ì´í…œ - ìš°ê¸°ì²  ì„ ì œì  ì ê²€ ëŒ€ìƒ")
                st.markdown("""
                <div style="background-color: #fff3cd; padding: 15px; border-radius: 8px; margin-bottom: 15px; border-left: 4px solid #ffc107;">
                    <h4>ğŸŒ§ï¸ ìš°ê¸°ì² (6ì›”~9ì›”) ì„ ì œì  ì ê²€ ëŒ€ìƒ ì„ ì •</h4>
                    <p>ìš°ê¸°ì²  ì¥ì•  ì§‘ì¤‘ë°œìƒ ì‚¬ì—…ì¥ì„ ë¶„ì„í•˜ì—¬ ì„ ì œì  ì ê²€ ëŒ€ìƒì„ ì¶”ì¶œí•©ë‹ˆë‹¤:</p>
                    <ul>
                        <li>ğŸ” <strong>ìš°ê¸°ì²  ì¥ì•  íŒ¨í„´ ë¶„ì„</strong>: 6ì›”~9ì›” ì¥ì•  ì´ë ¥ ë¶„ì„</li>
                        <li>âš ï¸ <strong>ê³ ìœ„í—˜ ì‚¬ì—…ì¥ ì„ ë³„</strong>: ìš°ê¸°ì²  ì¥ì•  2ê±´ ì´ìƒ ë°œìƒ ì‚¬ì—…ì¥</li>
                        <li>ğŸ¯ <strong>ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê³„ì‚°</strong>: ì¥ì• ê±´ìˆ˜ + ì›ì¸ë³„ ìœ„í—˜ë„ ê°€ì¤‘ì¹˜</li>
                        <li>ğŸ”§ <strong>ì„ ì œì  ì ê²€ ê¶Œì¥ì‚¬í•­</strong>: ì›ì¸ë³„ ë§ì¶¤í˜• ì ê²€ í•­ëª©</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)
                
                df = st.session_state.incident_history.copy()
                team_list = sorted(df['ìš´ìš©íŒ€'].dropna().unique())
                team_options = ['ì „ì²´ íŒ€'] + team_list
                selected_action_team = st.selectbox("ë¶„ì„í•  ìš´ìš©íŒ€ì„ ì„ íƒí•˜ì„¸ìš”", options=team_options, index=0, key='action_team_select')
                
                if selected_action_team != 'ì „ì²´ íŒ€':
                    st.markdown(f"### ğŸŒ§ï¸ {selected_action_team} ìš°ê¸°ì²  ì„ ì œì  ì ê²€ ëŒ€ìƒ ë¶„ì„")
                    
                    # ìš°ê¸°ì²  ë¶„ì„ ì‹¤í–‰
                    rainy_analysis = analyze_rainy_season_businesses(df, selected_action_team)
                    
                    if rainy_analysis is not None and not rainy_analysis.empty:
                        st.success(f"âœ… ìš°ê¸°ì²  ì¥ì•  ì§‘ì¤‘ë°œìƒ ì‚¬ì—…ì¥ {len(rainy_analysis)}ê°œ ë°œê²¬!")
                        
                        # ìš°ê¸°ì²  ë¶„ì„ í†µê³„ (ê°€ë¡œ ë°°ì¹˜)
                        st.markdown("#### ğŸ“Š ìš°ê¸°ì²  ë¶„ì„ í†µê³„")
                        stat_col1, stat_col2, stat_col3, stat_col4, stat_col5 = st.columns(5)
                        
                        with stat_col1:
                            total_rainy_incidents = rainy_analysis['ìš°ê¸°ì² _ì¥ì• ê±´ìˆ˜'].sum()
                            st.metric("ì´ ìš°ê¸°ì²  ì¥ì• ", f"{total_rainy_incidents}ê±´")
                        
                        with stat_col2:
                            avg_incidents = rainy_analysis['ìš°ê¸°ì² _ì¥ì• ê±´ìˆ˜'].mean()
                            st.metric("í‰ê·  ì¥ì• ê±´ìˆ˜", f"{avg_incidents:.1f}ê±´")
                        
                        with stat_col3:
                            max_incidents = rainy_analysis['ìš°ê¸°ì² _ì¥ì• ê±´ìˆ˜'].max()
                            st.metric("ìµœëŒ€ ì¥ì• ê±´ìˆ˜", f"{max_incidents}ê±´")
                        
                        with stat_col4:
                            total_businesses = len(rainy_analysis)
                            st.metric("ì„ ì œì  ì ê²€ ëŒ€ìƒ", f"{total_businesses}ê°œ")
                        
                        with stat_col5:
                            # ìš°ì„ ìˆœìœ„ ë¶„í¬ ìš”ì•½
                            priority_counts = rainy_analysis['ìš°ì„ ìˆœìœ„ì ìˆ˜'].apply(lambda x: 
                                'ğŸ”´ ë§¤ìš°ë†’ìŒ' if x >= 50 else
                                'ğŸŸ  ë†’ìŒ' if x >= 30 else
                                'ğŸŸ¡ ë³´í†µ' if x >= 15 else 'ğŸŸ¢ ë‚®ìŒ'
                            ).value_counts()
                            high_priority_count = priority_counts.get('ğŸ”´ ë§¤ìš°ë†’ìŒ', 0) + priority_counts.get('ğŸŸ  ë†’ìŒ', 0)
                            st.metric("ê³ ìœ„í—˜ ì‚¬ì—…ì¥", f"{high_priority_count}ê°œ")
                        
                        # ìš°ì„ ìˆœìœ„ ë¶„í¬ ìƒì„¸
                        st.markdown("**ğŸ”´ ìš°ì„ ìˆœìœ„ ë¶„í¬:**")
                        priority_dist_col1, priority_dist_col2, priority_dist_col3, priority_dist_col4 = st.columns(4)
                        
                        with priority_dist_col1:
                            st.write(f"ğŸ”´ ë§¤ìš°ë†’ìŒ: {priority_counts.get('ğŸ”´ ë§¤ìš°ë†’ìŒ', 0)}ê°œ")
                        with priority_dist_col2:
                            st.write(f"ğŸŸ  ë†’ìŒ: {priority_counts.get('ğŸŸ  ë†’ìŒ', 0)}ê°œ")
                        with priority_dist_col3:
                            st.write(f"ğŸŸ¡ ë³´í†µ: {priority_counts.get('ğŸŸ¡ ë³´í†µ', 0)}ê°œ")
                        with priority_dist_col4:
                            st.write(f"ğŸŸ¢ ë‚®ìŒ: {priority_counts.get('ğŸŸ¢ ë‚®ìŒ', 0)}ê°œ")
                        
                        # ì„ ì œì  ì ê²€ ëŒ€ìƒ ì‚¬ì—…ì¥ (ìš°ì„ ìˆœìœ„ë³„ í•„í„°ë§)
                        st.markdown("#### ğŸ¯ ì„ ì œì  ì ê²€ ëŒ€ìƒ ì‚¬ì—…ì¥ (ìš°ì„ ìˆœìœ„ë³„ í•„í„°ë§)")
                        
                        # ìš°ì„ ìˆœìœ„ í•„í„° ì¶”ê°€
                        priority_filter = st.selectbox(
                            "ìš°ì„ ìˆœìœ„ë³„ í•„í„°ë§",
                            options=['ì „ì²´', 'ğŸ”´ ë§¤ìš°ë†’ìŒ', 'ğŸŸ  ë†’ìŒ', 'ğŸŸ¡ ë³´í†µ', 'ğŸŸ¢ ë‚®ìŒ'],
                            index=0,
                            key="priority_filter"
                        )
                        
                        # ìš°ì„ ìˆœìœ„ë³„ í•„í„°ë§ ì ìš©
                        filtered_df = rainy_analysis.copy()
                        if priority_filter != 'ì „ì²´':
                            filtered_df['ìš°ì„ ìˆœìœ„_ë“±ê¸‰'] = filtered_df['ìš°ì„ ìˆœìœ„ì ìˆ˜'].apply(lambda x: 
                                'ğŸ”´ ë§¤ìš°ë†’ìŒ' if x >= 50 else
                                'ğŸŸ  ë†’ìŒ' if x >= 30 else
                                'ğŸŸ¡ ë³´í†µ' if x >= 15 else 'ğŸŸ¢ ë‚®ìŒ'
                            )
                            filtered_df = filtered_df[filtered_df['ìš°ì„ ìˆœìœ„_ë“±ê¸‰'] == priority_filter]
                        
                        if not filtered_df.empty:
                            # í‘œì‹œìš© ë°ì´í„°í”„ë ˆì„ ìƒì„±
                            display_df = filtered_df.copy()
                            
                            # ì£¼ìš”ì›ì¸ì„ í¼ì„¼íŠ¸ë¡œ í‘œì‹œ
                            def format_causes_percentage(causes_dict):
                                if not causes_dict:
                                    return ''
                                total = sum(causes_dict.values())
                                percentages = []
                                for cause, count in list(causes_dict.items())[:3]:  # ìƒìœ„ 3ê°œë§Œ
                                    percentage = round((count / total) * 100, 1)
                                    percentages.append(f"{cause}({percentage}%)")
                                return ', '.join(percentages)
                            
                            display_df['ì£¼ìš”ì›ì¸'] = display_df['ì›ì¸'].apply(format_causes_percentage)
                            
                            # ì„ ì œì  ì ê²€ì‚¬í•­ì„ ì£¼ìš” í•­ëª©ë§Œ í‘œì‹œ
                            def format_preventive_actions(actions_list):
                                if not actions_list:
                                    return ''
                                # ì£¼ìš” ì ê²€ í•­ëª©ë§Œ ì¶”ì¶œ (ì´ëª¨ì§€ ì œê±°í•˜ê³  í•µì‹¬ ë‚´ìš©ë§Œ)
                                key_items = []
                                for action in actions_list[:2]:  # ìƒìœ„ 2ê°œë§Œ
                                    # ì´ëª¨ì§€ì™€ íšŸìˆ˜ ì •ë³´ ì œê±°í•˜ê³  í•µì‹¬ ë‚´ìš©ë§Œ ì¶”ì¶œ
                                    clean_action = action.split('(')[0].replace('âš¡', '').replace('ğŸ”Œ', '').replace('ğŸ”§', '').replace('ğŸ”', '').strip()
                                    key_items.append(clean_action)
                                return ' | '.join(key_items)
                            
                            display_df['ì„ ì œì _ì ê²€ì‚¬í•­'] = display_df['ì„ ì œì _ì ê²€ì‚¬í•­'].apply(format_preventive_actions)
                            
                            # í‘œì‹œí•  ì»¬ëŸ¼ë§Œ ì„ íƒ
                            show_cols = ['ì‚¬ì—…ì¥ëª…', 'ìš°ê¸°ì² _ì¥ì• ê±´ìˆ˜', 'ìš°ì„ ìˆœìœ„ì ìˆ˜', 'ì£¼ìš”ì›ì¸', 'ì„ ì œì _ì ê²€ì‚¬í•­']
                            st.dataframe(display_df[show_cols], use_container_width=True)
                            
                            st.info(f"ğŸ“Š {priority_filter} ìš°ì„ ìˆœìœ„ ì‚¬ì—…ì¥: {len(filtered_df)}ê°œ")
                        else:
                            st.warning(f"âš ï¸ {priority_filter} ìš°ì„ ìˆœìœ„ ì‚¬ì—…ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
                        
                        # ìƒì„¸ ë¶„ì„
                        st.markdown("#### ğŸ” ìƒì„¸ ë¶„ì„ ë° ê¶Œì¥ì‚¬í•­")
                        
                        # ì„ íƒëœ ì‚¬ì—…ì¥ ìƒì„¸ ë¶„ì„ (í•„í„°ë§ëœ ë°ì´í„° ì‚¬ìš©)
                        if not filtered_df.empty:
                            selected_business = st.selectbox(
                                "ìƒì„¸ ë¶„ì„í•  ì‚¬ì—…ì¥ì„ ì„ íƒí•˜ì„¸ìš”",
                                options=filtered_df['ì‚¬ì—…ì¥ëª…'].tolist(),
                                key="action_business_select"
                            )
                            
                            if selected_business:
                                business_data = filtered_df[filtered_df['ì‚¬ì—…ì¥ëª…'] == selected_business].iloc[0]
                                st.markdown(f"##### ğŸ“‹ {selected_business} ìƒì„¸ ë¶„ì„")
                                
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.markdown("**ğŸ“Š ìš°ê¸°ì²  ì¥ì•  í˜„í™©:**")
                                    st.write(f"- ì´ ì¥ì• ê±´ìˆ˜: {business_data['ìš°ê¸°ì² _ì¥ì• ê±´ìˆ˜']}ê±´")
                                    st.write(f"- ìš°ì„ ìˆœìœ„ì ìˆ˜: {business_data['ìš°ì„ ìˆœìœ„ì ìˆ˜']}ì ")
                                    
                                    if business_data['ì›ì¸']:
                                        st.markdown("**ğŸ¯ ì£¼ìš” ì¥ì•  ì›ì¸:**")
                                        for cause, count in business_data['ì›ì¸'].items():
                                            st.write(f"- {cause}: {count}íšŒ")
                                
                                with col2:
                                    st.markdown("**ğŸ”§ ì„ ì œì  ì ê²€ ê¶Œì¥ì‚¬í•­:**")
                                    if business_data['ì„ ì œì _ì ê²€ì‚¬í•­']:
                                        for action in business_data['ì„ ì œì _ì ê²€ì‚¬í•­']:
                                            st.write(f"â€¢ {action}")
                                    else:
                                        st.write("â€¢ ì¢…í•© ì ê²€ ì‹¤ì‹œ")
                        
                        # í•„í„°ë§ëœ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
                        st.markdown("#### ğŸ“¥ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
                        
                        # ì—‘ì…€ í˜¸í™˜ì„±ì„ ìœ„í•œ ì¸ì½”ë”© ì²˜ë¦¬
                        csv_data = filtered_df.to_csv(index=False, encoding='cp949')
                        priority_suffix = f"_{priority_filter.replace('ğŸ”´', 'ë§¤ìš°ë†’ìŒ').replace('ğŸŸ ', 'ë†’ìŒ').replace('ğŸŸ¡', 'ë³´í†µ').replace('ğŸŸ¢', 'ë‚®ìŒ')}" if priority_filter != 'ì „ì²´' else ""
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.download_button(
                                f"ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ ({priority_suffix})",
                                csv_data,
                                file_name=f"{selected_action_team}_ìš°ê¸°ì² _ì„ ì œì ì ê²€ëŒ€ìƒ{priority_suffix}_{pd.Timestamp.now().strftime('%Y%m%d')}.csv",
                                mime="text/csv"
                            )
                        
                        with col2:
                            # ì—‘ì…€ íŒŒì¼ë¡œë„ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•˜ë„ë¡
                            excel_buffer = io.BytesIO()
                            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                                filtered_df.to_excel(writer, sheet_name='ìš°ê¸°ì² _ì„ ì œì ì ê²€ëŒ€ìƒ', index=False)
                            excel_buffer.seek(0)
                            
                            st.download_button(
                                f"ğŸ“Š Excel ë‹¤ìš´ë¡œë“œ ({priority_suffix})",
                                excel_buffer.getvalue(),
                                file_name=f"{selected_action_team}_ìš°ê¸°ì² _ì„ ì œì ì ê²€ëŒ€ìƒ{priority_suffix}_{pd.Timestamp.now().strftime('%Y%m%d')}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                    
                    else:
                        st.warning("âš ï¸ í•´ë‹¹ íŒ€ì˜ ìš°ê¸°ì²  ì¥ì•  ì´ë ¥ì´ ì—†ê±°ë‚˜ ë¶„ì„í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
                        st.info("ğŸ’¡ ë‹¤ë¥¸ íŒ€ì„ ì„ íƒí•˜ê±°ë‚˜ ë” ë§ì€ ì¥ì•  ì´ë ¥ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ë³´ì„¸ìš”.")
                else:
                    st.info("ìš´ìš©íŒ€ì„ ì„ íƒí•˜ë©´ ìš°ê¸°ì²  ì„ ì œì  ì ê²€ ëŒ€ìƒ ë¶„ì„ì´ ì‹œì‘ë©ë‹ˆë‹¤.")
    else:
        st.info("L2 SW ì¥ì•  ì´ë ¥ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")

# --- íƒ­ 2: ì‹¤ì‹œê°„ ì •ì „ì¥ì•  ---
with tab2:
    st.header("âš¡ ì‹¤ì‹œê°„ ì •ì „ì¥ì•  ê´€ë¦¬")
    
    # ì¥ë¹„ DB ì—…ë¡œë“œ ì„¹ì…˜
    with st.expander("âš™ï¸ ì¥ë¹„ DB ê´€ë¦¬", expanded=False):
        st.write("**ì¥ë¹„ ì„¤ì¹˜ í˜„í™© ë°ì´í„°ë² ì´ìŠ¤ ì—…ë¡œë“œ**")
        st.write("CSV íŒŒì¼ í˜•ì‹: ì£¼ì†Œ, ì¥ë¹„ìˆ˜ (ë˜ëŠ” ì‚¬ì—…ì¥ì£¼ì†Œ, ì„¤ì¹˜ëŒ“ìˆ˜ ë“±)")
        
        # ì €ì¥ëœ ì¥ë¹„ DB ì •ë³´ í‘œì‹œ
        success, metadata = get_equipment_db_metadata()
        if success:
            st.success(f"ğŸ’¾ **ì €ì¥ëœ ì¥ë¹„ DB ì •ë³´:**")
            st.write(f"ğŸ“… ì—…ë¡œë“œ ì‹œê°„: {metadata['upload_time'][:19]}")
            st.write(f"ğŸ“Š ì´ ë ˆì½”ë“œ: {metadata['total_records']:,}ê°œ")
            st.write(f"âš™ï¸ ì´ ì¥ë¹„: {metadata['total_equipment']:,}ëŒ€")
            st.write(f"ğŸ“‹ ì»¬ëŸ¼: {', '.join(metadata['columns'])}")
        
        col1, col2 = st.columns(2)
        
        with col1:
            equipment_file = st.file_uploader("ì¥ë¹„ DB CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"], key="equipment_db_uploader")
            
            if equipment_file is not None:
                equipment_df = read_csv_auto_encoding(equipment_file)
                if equipment_df is not None:
                    # ì»¬ëŸ¼ëª… ì •ê·œí™” ì˜ˆì‹œ
                    equipment_df.columns = [c.replace(' ', '').replace('\t', '').replace('\n', '') for c in equipment_df.columns]
                    
                    # ì¥ë¹„ DB ì»¬ëŸ¼ í‘œì¤€í™”
                    for col in equipment_df.columns:
                        if col in ['ì£¼ì†Œ', 'ì‚¬ì—…ì¥ì£¼ì†Œ', 'ì„¤ì¹˜ì£¼ì†Œ']:
                            equipment_df = equipment_df.rename(columns={col: 'ì£¼ì†Œ'})
                        if 'ìˆ˜' in col or 'ëŒ“ìˆ˜' in col or 'ê°œìˆ˜' in col:
                            equipment_df = equipment_df.rename(columns={col: 'ì¥ë¹„ìˆ˜'})
                    
                    st.session_state.equipment_db = equipment_df
                    st.success(f"ì¥ë¹„ DBê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. (ì´ {len(equipment_df)}ê°œ ì£¼ì†Œ, {equipment_df['ì¥ë¹„ìˆ˜'].fillna(0).astype(int).sum()}ëŒ€ ì¥ë¹„)")
                    
                    # ìë™ ì €ì¥
                    save_success, save_result = save_equipment_db(equipment_df)
                    if save_success:
                        st.success("ğŸ’¾ ì¥ë¹„ DBê°€ ìë™ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.warning(f"ì €ì¥ ì‹¤íŒ¨: {save_result}")
                    
                    # ë¯¸ë¦¬ë³´ê¸°
                    with st.expander("ì¥ë¹„ DB ë¯¸ë¦¬ë³´ê¸°"):
                        st.dataframe(equipment_df.head(10))
                else:
                    st.error("íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        with col2:
            # í˜„ì¬ ë¡œë“œëœ ì¥ë¹„ DB ìƒíƒœ
            if 'equipment_db' in st.session_state and st.session_state.equipment_db is not None:
                st.success(f"âœ… **í˜„ì¬ ë¡œë“œëœ ì¥ë¹„ DB:**")
                st.write(f"ğŸ“Š ì´ ë ˆì½”ë“œ: {len(st.session_state.equipment_db):,}ê°œ")
                st.write(f"âš™ï¸ ì´ ì¥ë¹„: {st.session_state.equipment_db['ì¥ë¹„ìˆ˜'].fillna(0).astype(int).sum():,}ëŒ€")
                
                # ìˆ˜ë™ ì €ì¥ ë²„íŠ¼
                if st.button("ğŸ’¾ ìˆ˜ë™ ì €ì¥", type="secondary", key="equipment_manual_save"):
                    save_success, save_result = save_equipment_db(st.session_state.equipment_db)
                    if save_success:
                        st.success("ì¥ë¹„ DBê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
                
                # ì¥ë¹„ DB ì œê±° ë²„íŠ¼
                if st.button("ğŸ—‘ï¸ ë©”ëª¨ë¦¬ì—ì„œ ì œê±°", key="equipment_remove_memory"):
                    st.session_state.equipment_db = None
                    st.success("ì¥ë¹„ DBê°€ ë©”ëª¨ë¦¬ì—ì„œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
                
                # ì €ì¥ëœ íŒŒì¼ ì‚­ì œ ë²„íŠ¼
                if st.button("ğŸ—‘ï¸ ì €ì¥ëœ íŒŒì¼ ì‚­ì œ", key="equipment_delete_file"):
                    delete_success, delete_result = delete_equipment_db()
                    if delete_success:
                        st.success("ì €ì¥ëœ ì¥ë¹„ DB íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
                    else:
                        st.error(f"ì‚­ì œ ì‹¤íŒ¨: {delete_result}")
            else:
                st.info("í˜„ì¬ ë¡œë“œëœ ì¥ë¹„ DBê°€ ì—†ìŠµë‹ˆë‹¤.")
                
                # ì €ì¥ëœ íŒŒì¼ì—ì„œ ë¡œë“œ ë²„íŠ¼
                if success:  # ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´
                    if st.button("ğŸ“‚ ì €ì¥ëœ íŒŒì¼ì—ì„œ ë¡œë“œ", key="equipment_load_file"):
                        load_success, load_result = load_equipment_db()
                        if load_success:
                            st.session_state.equipment_db = load_result
                            st.success("ì €ì¥ëœ ì¥ë¹„ DBê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.rerun()
                        else:
                            st.error(f"ë¡œë“œ ì‹¤íŒ¨: {load_result}")
    
    # ì‚¬ì—…ì¥ ê²€ìƒ‰ ì„¹ì…˜
    with st.expander("ğŸ” ì‚¬ì—…ì¥/ì£¼ì†Œ ê²€ìƒ‰", expanded=True):
        col1, col2 = st.columns([3, 1])
        with col1:
            search_query = st.text_input("ğŸ¢ ì‚¬ì—…ì¥ëª… ë˜ëŠ” ì£¼ì†Œë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ë¡¯ë°ë°±í™”ì , ë¶€ì‚°ê´‘ì—­ì‹œ í•´ìš´ëŒ€êµ¬...", key="search_input")
        with col2:
            region_filter = st.selectbox("ì§€ì—­", ["ì „ì²´", "ë¶€ì‚°", "ìš¸ì‚°", "ê²½ë‚¨"], key="region_filter")
        
        if st.button("ğŸ” ê²€ìƒ‰", type="secondary") and search_query:
            region = "" if region_filter == "ì „ì²´" else region_filter
            
            with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                results = search_business_kakao(search_query, region)
            
            if results:
                st.success(f"{len(results)}ê°œì˜ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                
                # ê²€ìƒ‰ ê¸°ë¡ ì €ì¥
                search_record = {
                    'timestamp': datetime.now(),
                    'query': search_query,
                    'region': region_filter,
                    'result_count': len(results)
                }
                st.session_state.search_history.append(search_record)
                
                # ê²°ê³¼ í‘œì‹œ
                for idx, place in enumerate(results[:5], 1):
                    with st.container():
                        col1, col2, col3 = st.columns([3, 1, 1])
                        with col1:
                            st.write(f"**{idx}. {place.get('place_name', 'N/A')}**")
                            primary_addr = place.get('primary_address', 'N/A')
                            road_addr = place.get('road_address_name', '')
                            addr_name = place.get('address_name', '')
                            if primary_addr and primary_addr != 'N/A':
                                st.write(f"ğŸ“ **ì£¼ì†Œ:** {primary_addr}")
                                if road_addr and road_addr != primary_addr:
                                    st.write(f"ğŸ›£ï¸ **ë„ë¡œëª…:** {road_addr}")
                            else:
                                st.write(f"ğŸ“ **ì£¼ì†Œ:** {road_addr or addr_name or 'N/A'}")
                            # ì „í™”ë²ˆí˜¸ í‘œì‹œ ë° ì„ì‹œ ì €ì¥
                            session_key = f"manual_contact_{idx}_{place.get('place_name', '')}_{primary_addr}"
                            # ì„¸ì…˜ ìƒíƒœì— ì„ì‹œ ì „í™”ë²ˆí˜¸ ì €ì¥
                            if 'manual_contacts' not in st.session_state:
                                st.session_state.manual_contacts = {}
                            phone = place.get('phone', '')
                            if not phone:
                                # ìˆ˜ë™ ì…ë ¥ê°’ì´ ìˆìœ¼ë©´ ìš°ì„ 
                                manual_contact = st.session_state.manual_contacts.get(session_key, '')
                                if manual_contact:
                                    phone = manual_contact
                                    phone_display = manual_contact
                                else:
                                    phone_display = 'ì¶”ê°€ ê²€ìƒ‰ í•„ìš”'
                            else:
                                phone_display = phone
                            st.write(f"ğŸ“ **ì „í™”:** {phone_display}")
                            if place.get('category_name'):
                                st.write(f"ğŸ·ï¸ **ë¶„ë¥˜:** {place.get('category_name')}")
                            # ì—°ë½ì²˜ ì¶”ê°€ ê²€ìƒ‰ ê¸°ëŠ¥
                            if not phone:
                                search_links = get_contact_search_links(
                                    place.get('place_name', ''),
                                    primary_addr or addr_name or road_addr
                                )
                                with st.expander("ğŸ” ì—°ë½ì²˜ ì¶”ê°€ ê²€ìƒ‰", expanded=False):
                                    st.write("**ì—°ë½ì²˜ ì •ë³´ë¥¼ ì°¾ê¸° ìœ„í•´ ë‹¤ìŒ ë§í¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:**")
                                    for link_text, link_url in search_links:
                                        st.link_button(link_text, link_url)
                                    # ìˆ˜ë™ ì—°ë½ì²˜ ì…ë ¥
                                    manual_contact = st.text_input(
                                        "ğŸ“ ì—°ë½ì²˜ ìˆ˜ë™ ì…ë ¥",
                                        placeholder="051-123-4567",
                                        key=session_key
                                    )
                                    if manual_contact:
                                        st.session_state.manual_contacts[session_key] = manual_contact
                                        st.success(f"ì—°ë½ì²˜ê°€ ì…ë ¥ë˜ì—ˆìŠµë‹ˆë‹¤: {manual_contact}")
                                        phone_display = manual_contact
                                        phone = manual_contact
                            else:
                                with st.expander("ğŸ” ë” ë§ì€ ì •ë³´ ê²€ìƒ‰", expanded=False):
                                    search_links = get_contact_search_links(
                                        place.get('place_name', ''),
                                        ''
                                    )
                                    for link_text, link_url in search_links:
                                        st.link_button(link_text, link_url)
                            # ì¥ë¹„ ìˆ˜ ë§¤í•‘ - primary_address ì‚¬ìš©
                            equipment_match = False
                            if 'equipment_db' in st.session_state and st.session_state.equipment_db is not None:
                                address = primary_addr or addr_name or road_addr
                                equipment_count, match_method = find_equipment_by_real_address(address, st.session_state.equipment_db)
                                if equipment_count != "ì •ë³´ì—†ìŒ":
                                    # ì¥ë¹„ ìˆ˜ê°€ ë„ˆë¬´ ë§ì€ ê²½ìš° ê²½ê³ 
                                    if int(equipment_count) > 100:
                                        st.write(f"âš™ï¸ **ì„¤ì¹˜ ì¥ë¹„:** {equipment_count}ëŒ€ ({match_method}) âš ï¸")
                                        st.warning(f"âš ï¸ ì¥ë¹„ ìˆ˜ê°€ ë§ìŠµë‹ˆë‹¤. ë§¤ì¹­ ì •í™•ë„ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                                    else:
                                        st.write(f"âš™ï¸ **ì„¤ì¹˜ ì¥ë¹„:** {equipment_count}ëŒ€ ({match_method})")
                                    equipment_match = True
                                else:
                                    st.write(f"âš™ï¸ **ì„¤ì¹˜ ì¥ë¹„:** ì •ë³´ì—†ìŒ")
                            else:
                                st.write(f"âš™ï¸ **ì„¤ì¹˜ ì¥ë¹„:** ì¥ë¹„ DB ë¯¸ì—…ë¡œë“œ")
                        
                        with col2:
                            if place.get('place_url'):
                                st.link_button("ìƒì„¸ì •ë³´", place['place_url'])
                        
                        with col3:
                            # ì¥ë¹„ ë§¤ì¹­ëœ ê²½ìš° ë°”ë¡œ ë©˜íŠ¸ ìƒì„±ìœ¼ë¡œ ì—°ê²°
                            if equipment_match:
                                if st.button(f"ğŸ“¢ ë©˜íŠ¸ ìƒì„±", key=f"ment_{idx}"):
                                    # ì¥ì•  ì‹ ê³ 
                                    incident_id = add_outage_incident(
                                        location=place.get('primary_address', '') or place.get('address_name', '') or place.get('road_address_name', ''),
                                        business_name=place.get('place_name', ''),
                                        contact=place.get('phone', ''),
                                        cause="ë¯¸í™•ì¸",
                                        equipment_count=int(equipment_count) if equipment_count != "ì •ë³´ì—†ìŒ" else 1,
                                        priority="ë†’ìŒ"
                                    )
                                    
                                    # ìë™ìœ¼ë¡œ ê³µìš©ë¶€ ì •ì „ ë©˜íŠ¸ ìƒì„±
                                    message_id = add_resident_message(
                                        incident={'id': incident_id, 'location': place.get('primary_address', '') or place.get('address_name', '') or place.get('road_address_name', ''), 'contact': place.get('phone', '')},
                                        message_type="power_outage",
                                        estimated_time="30ë¶„ ë‚´"
                                    )
                                    
                                    st.success(f"ğŸš¨ ì¥ì•  ì‹ ê³  ë° ë©˜íŠ¸ê°€ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                    st.success(f"ì¥ì•  ID: {incident_id}, ë©˜íŠ¸ ID: {message_id}")
                                    st.success("ì•„ë˜ 'ì…ì£¼ë¯¼ ëŒ€ì‘ ë©˜íŠ¸ ê´€ë¦¬' ì„¹ì…˜ì—ì„œ ìƒì„±ëœ ë©˜íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”!")
                                    st.rerun()
                            else:
                                # ì¼ë°˜ ì¥ì•  ì‹ ê³  (ì¥ë¹„ DB ë¯¸ë§¤ì¹­)
                                if st.button(f"âš¡ ì¥ì• ì‹ ê³ ", key=f"report_{idx}"):
                                    # ì¥ì•  ì‹ ê³ 
                                    incident_id = add_outage_incident(
                                        location=place.get('primary_address', '') or place.get('address_name', '') or place.get('road_address_name', ''),
                                        business_name=place.get('place_name', ''),
                                        contact=place.get('phone', ''),
                                        cause="ë¯¸í™•ì¸",
                                        equipment_count=1,
                                        priority="ë³´í†µ"
                                    )
                                    
                                    st.success(f"ì¥ì•  ì‹ ê³ ê°€ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {incident_id})")
                                    st.success("ì•„ë˜ 'ì…ì£¼ë¯¼ ëŒ€ì‘ ë©˜íŠ¸ ê´€ë¦¬' ì„¹ì…˜ì—ì„œ ë©˜íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”!")
                                    st.rerun()
                        
                        st.divider()
            else:
                st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
    
    # ì…ì£¼ë¯¼ ëŒ€ì‘ ë©˜íŠ¸ ê´€ë¦¬
    st.subheader("ğŸ“¢ KT í†µì‹ ì¥ë¹„ ì…ì£¼ë¯¼ ëŒ€ì‘ ë©˜íŠ¸ ê´€ë¦¬")
    
    # ë©˜íŠ¸ í…œí”Œë¦¿ í¸ì§‘
    with st.expander("âœï¸ KT í†µì‹ ì¥ë¹„ ë©˜íŠ¸ í…œí”Œë¦¿ í¸ì§‘", expanded=False):
        st.write("**KT í†µì‹ ì¥ë¹„ ì¥ì•  ëŒ€ì‘ì„ ìœ„í•œ ë©˜íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©ì ì •ì˜ë¡œ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**")
        st.write("**ì‚¬ìš© ê°€ëŠ¥í•œ ë³€ìˆ˜:** {location} (ìœ„ì¹˜), {contact} (ì—°ë½ì²˜), {estimated_time} (ì˜ˆìƒ ë³µêµ¬ ì‹œê°„)")
        
        # ë©˜íŠ¸ ìœ í˜• ì„ íƒ
        template_type = st.selectbox(
            "í¸ì§‘í•  ë©˜íŠ¸ ìœ í˜•",
            ["power_outage", "line_fault", "extended_outage"],
            format_func=lambda x: {
                "power_outage": "1. ê³µìš©ë¶€ ì •ì „ ë°œìƒ",
                "line_fault": "2. íšŒì„ /ì„ ë¡œ ì¥ì•  ë°œìƒ", 
                "extended_outage": "3. ì¥ì•  ì§€ì† ì•ˆë‚´ (30ë¶„ ê°„ê²©)"
            }[x]
        )
        
        # í˜„ì¬ í…œí”Œë¦¿ í‘œì‹œ
        current_template = st.session_state.message_templates[template_type]
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ğŸ“ ì œëª© í¸ì§‘:**")
            new_title = st.text_input(
                "ë©˜íŠ¸ ì œëª©",
                value=current_template['title'],
                key=f"title_{template_type}"
            )
        
        with col2:
            st.write("**ğŸ“‹ ë‚´ìš© í¸ì§‘:**")
            new_template = st.text_area(
                "ë©˜íŠ¸ ë‚´ìš©",
                value=current_template['template'],
                height=200,
                key=f"template_{template_type}"
            )
        
        # ë¯¸ë¦¬ë³´ê¸°
        if st.button("ğŸ‘€ ë¯¸ë¦¬ë³´ê¸°", key=f"preview_{template_type}"):
            sample_incident = {
                'location': 'ë¶€ì‚°ê´‘ì—­ì‹œ í•´ìš´ëŒ€êµ¬ ìš°ë™ 123-45',
                'contact': '051-123-4567'
            }
            
            try:
                preview_content = new_template.format(
                    location=sample_incident['location'],
                    contact=sample_incident['contact'],
                    estimated_time="30ë¶„ ë‚´"
                )
                
                st.write("**ğŸ“‹ ë¯¸ë¦¬ë³´ê¸°:**")
                st.text_area(
                    "ë¯¸ë¦¬ë³´ê¸° ê²°ê³¼",
                    value=preview_content,
                    height=150,
                    disabled=True
                )
            except Exception as e:
                st.error(f"í…œí”Œë¦¿ ì˜¤ë¥˜: {e}")
                st.info("ë³€ìˆ˜ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”. (ì˜ˆ: {location}, {contact}, {estimated_time})")
        
        # ì €ì¥ ë²„íŠ¼
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ’¾ í…œí”Œë¦¿ ì €ì¥", type="primary", key=f"save_{template_type}"):
                st.session_state.message_templates[template_type]['title'] = new_title
                st.session_state.message_templates[template_type]['template'] = new_template
                
                # íŒŒì¼ì— ì €ì¥
                save_success, save_result = save_message_templates(st.session_state.message_templates)
                if save_success:
                    st.success("í…œí”Œë¦¿ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                else:
                    st.warning(f"ë©”ëª¨ë¦¬ ì €ì¥ë¨, íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {save_result}")
                st.rerun()
        
        with col2:
            if st.button("ğŸ”„ ê¸°ë³¸ê°’ìœ¼ë¡œ ë³µì›", key=f"reset_{template_type}"):
                default_templates = get_default_message_templates()
                st.session_state.message_templates[template_type] = default_templates[template_type]
                
                # íŒŒì¼ì— ì €ì¥
                save_success, save_result = save_message_templates(st.session_state.message_templates)
                if save_success:
                    st.success("ê¸°ë³¸ê°’ìœ¼ë¡œ ë³µì›ë˜ì—ˆìŠµë‹ˆë‹¤!")
                else:
                    st.warning(f"ë©”ëª¨ë¦¬ ë³µì›ë¨, íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {save_result}")
                st.rerun()
        
        with col3:
            if st.button("ğŸ“¥ í…œí”Œë¦¿ ë‚´ë³´ë‚´ê¸°", key=f"export_{template_type}"):
                template_data = {
                    'type': template_type,
                    'title': current_template['title'],
                    'template': current_template['template'],
                    'export_time': datetime.now().isoformat()
                }
                st.download_button(
                    "JSON ë‹¤ìš´ë¡œë“œ",
                    json.dumps(template_data, ensure_ascii=False, indent=2),
                    file_name=f"ment_template_{template_type}.json",
                    mime="application/json"
                )
        
        # ì „ì²´ í…œí”Œë¦¿ ê´€ë¦¬
        st.write("---")
        st.write("**ğŸ“‹ ì „ì²´ í…œí”Œë¦¿ ê´€ë¦¬:**")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ’¾ ì „ì²´ í…œí”Œë¦¿ ì €ì¥", type="secondary"):
                save_success, save_result = save_message_templates(st.session_state.message_templates)
                if save_success:
                    st.success("ì „ì²´ í…œí”Œë¦¿ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                else:
                    st.error(f"ì €ì¥ ì‹¤íŒ¨: {save_result}")
        
        with col2:
            if st.button("ğŸ”„ ì „ì²´ ê¸°ë³¸ê°’ ë³µì›", type="secondary"):
                st.session_state.message_templates = get_default_message_templates()
                save_success, save_result = save_message_templates(st.session_state.message_templates)
                if save_success:
                    st.success("ì „ì²´ í…œí”Œë¦¿ì´ ê¸°ë³¸ê°’ìœ¼ë¡œ ë³µì›ë˜ì—ˆìŠµë‹ˆë‹¤!")
                else:
                    st.warning(f"ë©”ëª¨ë¦¬ ë³µì›ë¨, íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {save_result}")
                st.rerun()
        
        with col3:
            if st.button("ğŸ“¥ ì „ì²´ í…œí”Œë¦¿ ë‚´ë³´ë‚´ê¸°", type="secondary"):
                export_data = {
                    'templates': st.session_state.message_templates,
                    'export_time': datetime.now().isoformat(),
                    'version': '1.0'
                }
                st.download_button(
                    "ì „ì²´ JSON ë‹¤ìš´ë¡œë“œ",
                    json.dumps(export_data, ensure_ascii=False, indent=2),
                    file_name="all_message_templates.json",
                    mime="application/json"
                )
    
    # ìƒì„±ëœ ë©˜íŠ¸ ëª©ë¡
    if st.session_state.resident_messages:
        st.write("**ğŸ“‹ ìƒì„±ëœ ë©˜íŠ¸ ëª©ë¡:**")
        
        # ë©˜íŠ¸ ìœ í˜•ë³„ í•„í„°
        message_filter = st.selectbox("ë©˜íŠ¸ ìœ í˜• í•„í„°", ["ì „ì²´", "power_outage", "line_fault", "extended_outage"])
        
        filtered_messages = st.session_state.resident_messages
        if message_filter != "ì „ì²´":
            filtered_messages = [msg for msg in filtered_messages if msg['message_type'] == message_filter]
        
        for message in reversed(filtered_messages):  # ìµœì‹ ìˆœ
            with st.container():
                col1, col2, col3 = st.columns([1, 3, 1])
                
                with col1:
                    st.write(f"**ID: {message['id']}**")
                    st.write(f"**{message['title']}**")
                    st.write(f"â° {message['timestamp'].strftime('%m/%d %H:%M')}")
                
                with col2:
                    st.text_area(
                        f"ë©˜íŠ¸ ë‚´ìš© (ID: {message['id']})",
                        value=message['content'],
                        height=150,
                        disabled=True,
                        key=f"message_content_{message['id']}"
                    )
                
                with col3:
                    st.write(f"**ìƒíƒœ:** {message['status']}")
                    if message['estimated_time']:
                        st.write(f"**ì˜ˆìƒì‹œê°„:** {message['estimated_time']}")
                    
                    # ë©˜íŠ¸ ë³µì‚¬ ë²„íŠ¼
                    if st.button("ğŸ“‹ ë³µì‚¬", key=f"copy_{message['id']}"):
                        st.write("ë©˜íŠ¸ê°€ í´ë¦½ë³´ë“œì— ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.code(message['content'])
                    
                    # ë©˜íŠ¸ ì‚­ì œ ë²„íŠ¼
                    if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"delete_{message['id']}"):
                        st.session_state.resident_messages = [msg for msg in st.session_state.resident_messages if msg['id'] != message['id']]
                        st.success("ë©˜íŠ¸ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        st.rerun()
                
                st.divider()
    else:
        st.info("ìƒì„±ëœ ë©˜íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # 30ë¶„ ì´ìƒ ì§€ì†ëœ ì¥ì•  ìë™ ì•Œë¦¼
    extended_incidents = get_extended_outage_incidents()
    if extended_incidents:
        st.write("**âš ï¸ ì¥ê¸° ì§€ì† ì¥ì•  ì•Œë¦¼:**")
        for incident in extended_incidents:
            duration = datetime.now() - incident['timestamp']
            hours = int(duration.total_seconds() // 3600)
            minutes = int((duration.total_seconds() % 3600) // 60)
            
            st.warning(f"**ID {incident['id']}:** {incident['business_name']} - {hours}ì‹œê°„ {minutes}ë¶„ ì§€ì†")
            
            # 30ë¶„ ê°„ê²© ìë™ ë©˜íŠ¸ ìƒì„± ì œì•ˆ
            if should_send_extended_message(incident):
                if st.button(f"ğŸ”„ 30ë¶„ ê°„ê²© ë©˜íŠ¸ ìƒì„± (ID: {incident['id']})", key=f"auto_extended_{incident['id']}"):
                    estimated_time = f"{hours + 1}ì‹œê°„ ë‚´"
                    message_id = add_resident_message(incident, "extended_outage", estimated_time)
                    st.success(f"30ë¶„ ê°„ê²© ë©˜íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {message_id})")
                    st.rerun()
    
    # ìµœê·¼ ê²€ìƒ‰ ê¸°ë¡
    if st.session_state.search_history:
        with st.expander("ğŸ“ˆ ìµœê·¼ ê²€ìƒ‰ ê¸°ë¡"):
            for record in reversed(st.session_state.search_history[-10:]):  # ìµœê·¼ 10ê°œ
                st.write(f"ğŸ• {record['timestamp'].strftime('%m/%d %H:%M')} - "
                        f"'{record['query']}' ({record['region']}) - {record['result_count']}ê±´")

# --- íƒ­ 3: ì‚¬ì—…ì¥ ë§¤í•‘ ---
with tab3:
    st.header("ğŸ“‹ ì‚¬ì—…ì¥ ëŒ€ìƒ ë§¤í•‘")
    
    # ì„œë¸Œíƒ­ ìƒì„±
    subtab1, subtab2 = st.tabs(["ğŸ”Œ ì˜ˆê³ ì •ì „ ë§¤í•‘", "ğŸ“ ì—°ë½ì²˜ ë§¤í•‘"])
    
    with subtab1:
        st.subheader("ğŸ”Œ ì˜ˆê³ ì •ì „ ëŒ€ìƒ ë§¤í•‘")
        col1, col2 = st.columns(2)
        with col1:
            outage_file = st.file_uploader("ì •ì „ëŒ€ìƒ CSV ì—…ë¡œë“œ", type=["csv"], key="outage")
        with col2:
            equipment_file = st.file_uploader("l2ìƒ˜í”Œ(ì¥ë¹„DB) CSV ì—…ë¡œë“œ", type=["csv"], key="equipment")

    skiprows = 0
    if outage_file is not None:
        preview = None
        for enc in ['utf-8', 'euc-kr', 'cp949']:
            try:
                outage_file.seek(0)
                preview = outage_file.getvalue().decode(enc)
                break
            except Exception:
                continue
        if preview is not None:
            with st.expander("CSV ë¯¸ë¦¬ë³´ê¸° ë³´ê¸°"):
                lines = preview.splitlines()
                for i, line in enumerate(lines[:10]):
                    st.write(f"{i}: {line}")
        skiprows = st.number_input("ë°ì´í„° ì‹œì‘ ì „ ê±´ë„ˆë›¸ ì¤„ ìˆ˜", min_value=0, max_value=20, value=0)

    if st.button("ğŸ”„ ì£¼ì†Œ ë§¤í•‘ ì‹¤í–‰", type="primary"):
        if outage_file and equipment_file:
            with st.spinner("ë§¤í•‘ ì²˜ë¦¬ ì¤‘..."):
                outage_df = read_csv_auto_encoding(outage_file, skiprows=skiprows)
                equipment_df = read_csv_auto_encoding(equipment_file)
                
                if outage_df is None or equipment_df is None:
                    st.stop()
                
                # ì»¬ëŸ¼ëª… ì •ê·œí™”
                outage_df.columns = [normalize_colname(c) for c in outage_df.columns]
                equipment_df.columns = [normalize_colname(c) for c in equipment_df.columns]
                
                # ì¥ë¹„ DB ì»¬ëŸ¼ í‘œì¤€í™”
                for col in equipment_df.columns:
                    if col in ['ì£¼ì†Œ', 'ì‚¬ì—…ì¥ì£¼ì†Œ']:
                        equipment_df = equipment_df.rename(columns={col: 'ì£¼ì†Œ'})
                    if 'ìˆ˜' in col:
                        equipment_df = equipment_df.rename(columns={col: 'ì¥ë¹„ìˆ˜'})
                
                # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
                required_cols = ['ì¼ì', 'ìš”ì¼', 'ì‹œê°„', 'ê³ ê°ëª…']
                missing_cols = [col for col in required_cols if col not in outage_df.columns]
                if missing_cols:
                    st.error(f"ì •ì „ëŒ€ìƒ CSVì— ë‹¤ìŒ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤: {missing_cols}")
                    st.stop()
                
                # ë§¤í•‘ ì²˜ë¦¬
                progress_bar = st.progress(0)
                results = []
                total_rows = len(outage_df)
                
                # ì—°ë½ì²˜ ê²€ìƒ‰ ì˜µì…˜
                enhanced_search = st.checkbox("ğŸ” í–¥ìƒëœ ì—°ë½ì²˜ ê²€ìƒ‰ ì‚¬ìš© (ë„¤ì´ë²„/êµ¬ê¸€ ê²€ìƒ‰ í¬í•¨)", value=True)
                
                for idx, row in outage_df.iterrows():
                    progress_bar.progress((idx + 1) / total_rows)
                    
                    date = str(row['ì¼ì']).strip()
                    weekday = str(row['ìš”ì¼']).strip()
                    time_ = str(row['ì‹œê°„']).strip()
                    customer_name = str(row['ê³ ê°ëª…']).strip()
                    
                    # ê¸°ë³¸ ì¹´ì¹´ì˜¤ API ê²€ìƒ‰
                    address, phone, _ = search_kakao_api_region(customer_name)
                    
                    # í–¥ìƒëœ ì—°ë½ì²˜ ê²€ìƒ‰ ì‚¬ìš© ì‹œ
                    if enhanced_search and (phone == 'ì •ë³´ì—†ìŒ' or phone == ''):
                        contact_info = search_contact_enhanced(customer_name, address)
                        if contact_info['phone']:
                            phone = contact_info['phone']
                            source_info = f"ì¹´ì¹´ì˜¤ API â†’ {contact_info['source']}"
                        else:
                            source_info = "ì¹´ì¹´ì˜¤ API"
                    else:
                        source_info = "ì¹´ì¹´ì˜¤ API"
                    
                    equipment_count, match_method = find_equipment_by_real_address(address, equipment_df)
                    
                    results.append({
                        'ì¼ì': date,
                        'ìš”ì¼': weekday,
                        'ì‹œê°„': time_,
                        'ê³ ê°ëª…': customer_name,
                        'ì‹¤ì œì£¼ì†Œ': address,
                        'ì „í™”ë²ˆí˜¸': phone,
                        'ê²€ìƒ‰ì†ŒìŠ¤': source_info,
                        'ì´ì¥ë¹„ìˆ˜': equipment_count,
                        'ë§¤ì¹­ë°©ë²•': match_method
                    })
                
                result_df = pd.DataFrame(results)
                
                # ë°ì´í„° íƒ€ì… ë³€í™˜ìœ¼ë¡œ PyArrow ì˜¤ë¥˜ ë°©ì§€
                try:
                    # ì´ì¥ë¹„ìˆ˜ ì»¬ëŸ¼ì„ ìˆ«ìë¡œ ë³€í™˜ (ë¬¸ìì—´ì€ NaNìœ¼ë¡œ ì²˜ë¦¬)
                    result_df['ì´ì¥ë¹„ìˆ˜'] = pd.to_numeric(result_df['ì´ì¥ë¹„ìˆ˜'], errors='coerce')
                    # NaN ê°’ì„ 'ì •ë³´ì—†ìŒ'ìœ¼ë¡œ ë‹¤ì‹œ ë³€í™˜
                    result_df['ì´ì¥ë¹„ìˆ˜'] = result_df['ì´ì¥ë¹„ìˆ˜'].fillna('ì •ë³´ì—†ìŒ')
                except Exception as e:
                    st.warning(f"ë°ì´í„° íƒ€ì… ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
                
                progress_bar.empty()
                
                # ê²°ê³¼ í‘œì‹œ
                st.success("ë§¤í•‘ ì™„ë£Œ!")
                st.dataframe(result_df, use_container_width=True)
                
                # í†µê³„
                total = len(result_df)
                address_success = len(result_df[result_df['ì‹¤ì œì£¼ì†Œ'] != 'ì •ë³´ì—†ìŒ'])
                phone_success = len(result_df[result_df['ì „í™”ë²ˆí˜¸'] != 'ì •ë³´ì—†ìŒ'])
                equipment_success = len(result_df[result_df['ì´ì¥ë¹„ìˆ˜'] != 'ì •ë³´ì—†ìŒ'])
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ì „ì²´ ê±´ìˆ˜", total)
                with col2:
                    st.metric("ì£¼ì†Œ ë§¤í•‘ ì„±ê³µ", address_success, f"{address_success/total*100:.1f}%")
                with col3:
                    st.metric("ì—°ë½ì²˜ ë§¤í•‘ ì„±ê³µ", phone_success, f"{phone_success/total*100:.1f}%")
                with col4:
                    st.metric("ì¥ë¹„ ë§¤ì¹­ ì„±ê³µ", equipment_success, f"{equipment_success/total*100:.1f}%")
                
                # ì—°ë½ì²˜ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ë¶„ì„
                if enhanced_search:
                    st.subheader("ğŸ“Š ì—°ë½ì²˜ ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„")
                    
                    # ê²€ìƒ‰ ì†ŒìŠ¤ë³„ í†µê³„
                    source_stats = result_df['ê²€ìƒ‰ì†ŒìŠ¤'].value_counts()
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("**ğŸ” ê²€ìƒ‰ ì†ŒìŠ¤ë³„ ì„±ê³µë¥ :**")
                        for source, count in source_stats.items():
                            percentage = (count / total) * 100
                            st.write(f"- {source}: {count}ê±´ ({percentage:.1f}%)")
                    
                    with col2:
                        st.write("**ğŸ“ ì—°ë½ì²˜ ë¯¸ë°œê²¬ ê±´ìˆ˜:**")
                        no_phone = len(result_df[result_df['ì „í™”ë²ˆí˜¸'] == 'ì •ë³´ì—†ìŒ'])
                        st.write(f"- ì—°ë½ì²˜ ì—†ìŒ: {no_phone}ê±´")
                        if no_phone > 0:
                            st.write("**ë¯¸ë°œê²¬ ê³ ê°ëª…:**")
                            no_phone_customers = result_df[result_df['ì „í™”ë²ˆí˜¸'] == 'ì •ë³´ì—†ìŒ']['ê³ ê°ëª…'].tolist()
                            for customer in no_phone_customers[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                                st.write(f"  â€¢ {customer}")
                            if len(no_phone_customers) > 5:
                                st.write(f"  â€¢ ... ì™¸ {len(no_phone_customers) - 5}ê±´")
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ë“¤
                col1, col2 = st.columns(2)
                
                with col1:
                    # ê¸°ë³¸ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
                    csv = result_df.to_csv(index=False, encoding='cp949')
                    st.download_button("ğŸ“¥ ë§¤í•‘ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", csv, file_name="ì˜ˆê³ ì •ì „_ë§¤í•‘ê²°ê³¼.csv", mime="text/csv")
                
                with col2:
                    # ì—°ë½ì²˜ ì—…ë°ì´íŠ¸ëœ ì›ë³¸ CSV ë‹¤ìš´ë¡œë“œ
                    if enhanced_search:
                        updated_original = update_csv_with_contacts(result_df, outage_df)
                        updated_csv = updated_original.to_csv(index=False, encoding='cp949')
                        st.download_button("ğŸ“¥ ì—°ë½ì²˜ ì—…ë°ì´íŠ¸ëœ ì›ë³¸ CSV", updated_csv, file_name="ì˜ˆê³ ì •ì „_ì—°ë½ì²˜ì—…ë°ì´íŠ¸.csv", mime="text/csv")
        else:
            st.warning("ë‘ ê°œì˜ CSV íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    
    with subtab2:
        st.subheader("ğŸ“ ì—°ë½ì²˜ ë§¤í•‘")
        st.write("ì—‘ì…€ íŒŒì¼ì— ì—…ë¡œë“œëœ ì‚¬ì—…ì¥ ì •ë³´ë¥¼ API ê²€ìƒ‰ìœ¼ë¡œ ì—°ë½ì²˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤. (ì‚¬ì—…ì¥ëª… í‚¤ì›Œë“œ ì¶”ì¶œ + ëŒ€í‘œì¥ë¹„ ì£¼ì†Œ ê¸°ì¤€)")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        contact_file = st.file_uploader("ì—°ë½ì²˜ ì¶”ê°€í•  ì—‘ì…€/CSV íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx", "xls", "csv"], key="contact_mapping")
        
        if contact_file is not None:
            # íŒŒì¼ ì½ê¸°
            if contact_file.name.endswith(('.xlsx', '.xls')):
                import pandas as pd
                df = pd.read_excel(contact_file)
            else:
                df = read_csv_auto_encoding(contact_file)
            
            if df is not None:
                st.success(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {len(df)}ê±´")
                
                # ì»¬ëŸ¼ ì„ íƒ
                st.write("**ğŸ“‹ ì»¬ëŸ¼ ë§¤í•‘ ì„¤ì •**")
                col1, col2, col3 = st.columns(3)
                with col1:
                    h_col = st.selectbox("ì‚¬ì—…ì¥ëª…(Hì—´) ì»¬ëŸ¼ ì„ íƒ", options=df.columns.tolist(), key="h_col")
                with col2:
                    m_col = st.selectbox("ëŒ€í‘œì¥ë¹„ ì£¼ì†Œ(Mì—´) ì»¬ëŸ¼ ì„ íƒ", options=df.columns.tolist(), key="m_col")
                with col3:
                    n_col = st.selectbox("ì—°ë½ì²˜ìµœì¢…(Nì—´) ì»¬ëŸ¼ ì„ íƒ(ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)", options=['ìƒˆ ì»¬ëŸ¼ ìƒì„±'] + df.columns.tolist(), key="n_col")
                
                region_filter = st.selectbox("ê²€ìƒ‰ ì§€ì—­ í•„í„°", options=['ì „ì²´', 'ë¶€ì‚°', 'ê²½ë‚¨'], key="contact_region")
                enhanced_search = st.checkbox("ğŸ” í–¥ìƒëœ ì—°ë½ì²˜ ê²€ìƒ‰ ì‚¬ìš© (ë„¤ì´ë²„/êµ¬ê¸€ ê²€ìƒ‰ í¬í•¨)", value=True, key="contact_enhanced")
                
                def extract_keyword(biz_name):
                    import re
                    m = re.search(r'([ê°€-í£A-Za-z]+)$', str(biz_name))
                    return m.group(1) if m else str(biz_name)
                
                if st.button("ğŸ“ ì—°ë½ì²˜ ë§¤í•‘ ì‹¤í–‰", type="primary"):
                    with st.spinner("ì—°ë½ì²˜ ë§¤í•‘ ì²˜ë¦¬ ì¤‘..."):
                        progress_bar = st.progress(0)
                        results = []
                        total_rows = len(df)
                        
                        # Nì—´ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                        if n_col == 'ìƒˆ ì»¬ëŸ¼ ìƒì„±':
                            n_col_name = 'ì—°ë½ì²˜ìµœì¢…'
                            df[n_col_name] = ''
                        else:
                            n_col_name = n_col
                        
                        for idx, row in df.iterrows():
                            progress_bar.progress((idx + 1) / total_rows)
                            biz_name_raw = row[h_col]
                            keyword = extract_keyword(biz_name_raw)
                            address = str(row[m_col])
                            # ì¹´ì¹´ì˜¤ API ê²€ìƒ‰
                            search_result = search_business_kakao(keyword, address)
                            phone = search_result[0]['phone'] if search_result and search_result[0].get('phone') else ''
                            # í–¥ìƒëœ ê²€ìƒ‰
                            if (not phone or phone == 'ì •ë³´ì—†ìŒ') and enhanced_search:
                                contact_info = search_contact_enhanced(keyword, address)
                                phone = contact_info['phone'] if contact_info['phone'] else 'ì •ë³´ì—†ìŒ'
                            if not phone:
                                phone = 'ì •ë³´ì—†ìŒ'
                            df.at[idx, n_col_name] = phone
                        
                        st.success(f"ì—°ë½ì²˜ ë§¤í•‘ ì™„ë£Œ: {len(df)}ê±´")
                        st.dataframe(df, use_container_width=True)
                        
                        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                        col1, col2 = st.columns(2)
                        with col1:
                            if contact_file.name.endswith(('.xlsx', '.xls')):
                                import io
                                output = io.BytesIO()
                                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                                    df.to_excel(writer, index=False, sheet_name='ì—°ë½ì²˜ë§¤í•‘ê²°ê³¼')
                                output.seek(0)
                                st.download_button(
                                    "ğŸ“¥ ì—°ë½ì²˜ ë§¤í•‘ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Excel)",
                                    output.getvalue(),
                                    file_name="ì—°ë½ì²˜_ë§¤í•‘ê²°ê³¼.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                            else:
                                csv = df.to_csv(index=False, encoding='cp949')
                                st.download_button(
                                    "ğŸ“¥ ì—°ë½ì²˜ ë§¤í•‘ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)",
                                    csv,
                                    file_name="ì—°ë½ì²˜_ë§¤í•‘ê²°ê³¼.csv",
                                    mime="text/csv"
                                )
                        with col2:
                            success_count = len(df[df[n_col_name] != 'ì •ë³´ì—†ìŒ'])
                            st.info(f"âœ… ì„±ê³µ: {success_count}ê±´\nâŒ ì‹¤íŒ¨: {len(df) - success_count}ê±´")
            else:
                st.error("íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# --- ì‚¬ì´ë“œë°” ---
with st.sidebar:
    st.header("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ ë° ë°ì´í„° ê´€ë¦¬")
    # í†µí•© ë°ì´í„° ì—…ë¡œë“œ ì„¹ì…˜
    st.subheader("ğŸ“ ë°ì´í„° ì—…ë¡œë“œ/DB ê´€ë¦¬")
    # ì¥ì•  ì´ë ¥ CSV ì—…ë¡œë“œ
    incident_file = st.file_uploader("ì¥ì•  ì´ë ¥ CSV ì—…ë¡œë“œ", type=["csv"], key="sidebar_incident")
    if incident_file is not None:
        incident_df = read_csv_auto_encoding(incident_file)
        if incident_df is not None:
            incident_df.columns = [normalize_colname(c) for c in incident_df.columns]
            st.session_state.incident_history = incident_df
            st.session_state.incident_file = incident_file.getvalue()  # íŒŒì¼ ì›ë³¸ ì €ì¥
            st.success(f"ì¥ì•  ì´ë ¥ {len(incident_df)}ê±´ ì—…ë¡œë“œë¨ (ëª¨ë“  íƒ­ì—ì„œ ì‚¬ìš© ê°€ëŠ¥)")
        else:
            st.session_state.incident_history = None
            st.session_state.incident_file = None
            st.error("ì¥ì•  ì´ë ¥ CSV íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    # ì¥ë¹„ DB CSV ì—…ë¡œë“œ
    equipment_file = st.file_uploader("ì¥ë¹„ DB CSV ì—…ë¡œë“œ", type=["csv"], key="sidebar_equipment")
    if equipment_file is not None:
        equipment_df = read_csv_auto_encoding(equipment_file)
        if equipment_df is not None:
            equipment_df.columns = [c.replace(' ', '').replace('\t', '').replace('\n', '') for c in equipment_df.columns]
            st.session_state.equipment_db = equipment_df
            st.session_state.equipment_file = equipment_file.getvalue()  # íŒŒì¼ ì›ë³¸ ì €ì¥
            st.success(f"ì¥ë¹„ DB {len(equipment_df)}ê±´ ì—…ë¡œë“œë¨ (ëª¨ë“  íƒ­ì—ì„œ ì‚¬ìš© ê°€ëŠ¥)")
        else:
            st.session_state.equipment_db = None
            st.session_state.equipment_file = None
            st.error("ì¥ë¹„ DB CSV íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    # ëŒ€í˜•ì‚¬ì—…ì¥ ì¥ì• ëŒ€ì‘ ì—‘ì…€ ì—…ë¡œë“œ
    largebiz_file = st.file_uploader("ëŒ€í˜•ì‚¬ì—…ì¥ ì¥ì• ëŒ€ì‘ ì—‘ì…€ ì—…ë¡œë“œ", type=["xlsx", "xls"], key="sidebar_largebiz")
    if largebiz_file is not None:
        import pandas as pd
        try:
            largebiz_df = pd.read_excel(largebiz_file)
            largebiz_df.columns = [c.strip().replace('\n', '').replace('\t', '') for c in largebiz_df.columns]
            st.session_state.largebiz_db = largebiz_df
            st.session_state.largebiz_file = largebiz_file.getvalue()  # íŒŒì¼ ì›ë³¸ ì €ì¥
            st.success(f"ëŒ€í˜•ì‚¬ì—…ì¥ DB {len(largebiz_df)}ê±´ ì—…ë¡œë“œë¨ (ëª¨ë“  íƒ­ì—ì„œ ì‚¬ìš© ê°€ëŠ¥)")
        except Exception as e:
            st.session_state.largebiz_db = None
            st.session_state.largebiz_file = None
            st.error(f"ì—‘ì…€ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")


# --- íƒ­ 4: ëŒ€í˜•ì‚¬ì—…ì¥ ì¥ì• ëŒ€ì‘ ---
with tab4:
    st.header("ğŸ¢ ëŒ€í˜•ì‚¬ì—…ì¥ ì¥ì• ëŒ€ì‘")
    if 'largebiz_db' in st.session_state and st.session_state.largebiz_db is not None:
        df = st.session_state.largebiz_db.copy()
        # ìš´ìš©íŒ€.1 ê¸°ì¤€ìœ¼ë¡œ selectbox ìƒì„±
        team_list = sorted(df['ìš´ìš©íŒ€.1'].dropna().unique())
        selected_team = st.selectbox("ìš´ìš©íŒ€ì„ ì„ íƒí•˜ì„¸ìš”", options=['ìš´ìš©íŒ€ì„ ì„ íƒí•˜ì„¸ìš”'] + team_list, index=0, key="largebiz_team_select")
        if selected_team != 'ìš´ìš©íŒ€ì„ ì„ íƒí•˜ì„¸ìš”':
            filtered_df = df[df['ìš´ìš©íŒ€.1'] == selected_team]
            # ìš´ìš©íŒ€.1 ì»¬ëŸ¼ ìœ„ì¹˜ ì°¾ê¸°
            cols = filtered_df.columns.tolist()
            if 'ìš´ìš©íŒ€.1' in cols:
                idx = cols.index('ìš´ìš©íŒ€.1')
                show_cols = cols[idx+1:]
                show_cols = ['ìš´ìš©íŒ€.1'] + show_cols
            else:
                show_cols = cols
            st.dataframe(filtered_df[show_cols], use_container_width=True)
        else:
            st.info("ìš´ìš©íŒ€ì„ ì„ íƒí•˜ë©´ ëŒ€í˜•ì‚¬ì—…ì¥ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    else:
        st.info("ì‚¬ì´ë“œë°”ì—ì„œ ëŒ€í˜•ì‚¬ì—…ì¥ ì¥ì• ëŒ€ì‘ ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

# í•˜ë‹¨ ì •ë³´
st.markdown("---")
st.markdown("**ğŸ–§ L2 ìŠ¤ìœ„ì¹˜ ì¥ì•  í†µí•© ë¶„ì„ ì†”ë£¨ì…˜**")
# ìš°ì¸¡ í•˜ë‹¨ ë””ë ‰í„° ì •ë³´
st.markdown('<div style="text-align: right; color: #888; font-size: 0.9em;">ì¤‘ë¶€ì‚°ìš´ìš©íŒ€ AI TF(DANDI)<br><span style="font-size:0.8em; color:#bbb;">ê¹€ë™í˜„, ìœ¤ì„±í˜„, ì´íƒœí¬</span></div>', unsafe_allow_html=True)
    
# DB ìƒíƒœ ìš”ì•½ (ì—…ë¡œë“œ íŒŒì¼ ê¸°ì¤€ìœ¼ë¡œë§Œ í‘œì‹œ)
st.divider()
st.subheader("DB ìƒíƒœ ìš”ì•½")
if 'incident_history' in st.session_state and st.session_state.incident_history is not None:
    st.write(f"ì¥ì•  ì´ë ¥: {len(st.session_state.incident_history)}ê±´")
    if 'incident_file' in st.session_state and st.session_state.incident_file:
        st.download_button(
            "ìµœì¢… ì—…ë¡œë“œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            st.session_state.incident_file,
            file_name="ìµœì¢…_ì¥ì• ì´ë ¥.csv",
            mime="text/csv"
        )
else:
    st.write("ì¥ì•  ì´ë ¥: ì—†ìŒ")
if 'equipment_db' in st.session_state and st.session_state.equipment_db is not None:
    st.write(f"ì¥ë¹„ DB: {len(st.session_state.equipment_db)}ê±´")
    if 'equipment_file' in st.session_state and st.session_state.equipment_file:
        st.download_button(
            "ìµœì¢… ì—…ë¡œë“œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            st.session_state.equipment_file,
            file_name="ìµœì¢…_ì¥ë¹„DB.csv",
            mime="text/csv"
        )
else:
    st.write("ì¥ë¹„ DB: ì—†ìŒ")
if 'largebiz_db' in st.session_state and st.session_state.largebiz_db is not None:
    st.write(f"ëŒ€í˜•ì‚¬ì—…ì¥ DB: {len(st.session_state.largebiz_db)}ê±´")
    if 'largebiz_file' in st.session_state and st.session_state.largebiz_file:
        st.download_button(
            "ìµœì¢… ì—…ë¡œë“œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            st.session_state.largebiz_file,
            file_name="ìµœì¢…_ëŒ€í˜•ì‚¬ì—…ì¥_DB.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
else:
    st.write("ëŒ€í˜•ì‚¬ì—…ì¥ DB: ì—†ìŒ")
    